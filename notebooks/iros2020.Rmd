---
title: "IROS 2020"
output:
  html_document:
    theme: readable
    code_folding: hide
    df_print: kable
    toc: true
    toc_depth: 2
    toc_float: true
---

TODO: Create better response plots such as the ones seen in:

1. [Example plots](https://mjskay.github.io/tidybayes/articles/tidy-brms.html#posterior-predictions-kruschke-style)
1. [Responses for multilevel models](https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/multilevel-models.html)
1. [Responses for count/binary models](https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/counting-and-classification.html#binomial-regression)

```{r message=FALSE, warning=FALSE}
library(readr)
library(ggplot2)
library(broom)
library(reshape)
library(car)
library(interplot)
library(multcomp)
library(pastecs)
library(nlme)
library(stats)
library(plyr)
library(ggsignif)
library(PMCMR)
library(lmtest)
library(lme4)
library(dplyr)
library(brms)
library(jtools)
library(ggiraph)
library(ggiraphExtra)
library(modelr)
library(bayesplot)
library(tidybayes)

# # Setup for multiprocessing
# library(future)
# plan(multiprocess)
```
```{r}
train_models = F
```
```{r, message=FALSE, warning=FALSE}
data_folder = "~/Documents/GT/Research/Data/arbitration/2019-12-09/results"
# Load the CSV files
users = read_csv(
  file.path(data_folder, "users.csv"),
  col_types = cols(
    study_condition = col_factor(),
    noise_level = col_factor(ordered = T),
    age_group = col_factor(levels = seq(from = 0, to = 8), ordered = T),
    robot_experience = col_factor(levels = seq(from = 0, to = 4), ordered = T)
  )
)

actions = read_csv(
  file.path(data_folder, "actions.csv"),
  col_types = cols(
    study_condition = col_factor(),
    noise_level = col_factor(ordered = T),
    age_group = col_factor(levels = seq(from = 0, to = 8), ordered = T),
    robot_experience = col_factor(levels = seq(from = 0, to = 4), ordered = T)
  )
)

# Relabel the factors
users$study_condition = mapvalues(users$study_condition,
                                  from = seq(from = 1, to = 10),
                                  to = c("1"="BASELINE",
                                         "2"="DX_100", "3"="AX_100", "4"="DXAX_100",
                                         "5"="DX_90", "6"="AX_90", "7"="DXAX_90",
                                         "8"="DX_80", "9"="AX_80", "10"="DXAX_80"))
actions$study_condition = mapvalues(actions$study_condition,
                                    from = seq(from = 1, to = 10),
                                    to = c("1"="BASELINE",
                                           "2"="DX_100", "3"="AX_100", "4"="DXAX_100",
                                           "5"="DX_90", "6"="AX_90", "7"="DXAX_90",
                                           "8"="DX_80", "9"="AX_80", "10"="DXAX_80"))

# # Relevel the non-binary age
users$gender[users$gender == 'U'] = 'M'
actions$gender[actions$gender == 'U'] = 'M'

# Change binary responses to integers
users$scenario_completed = as.integer(users$scenario_completed)
actions$scenario_completed = as.integer(actions$scenario_completed)

actions$optimal_ax = as.integer(actions$optimal_ax)
actions$chose_ax = as.integer(actions$chose_ax)

actions$optimal_dx = as.integer(actions$optimal_dx)
actions$chose_dx = as.integer(actions$optimal_dx)

# Relabel user ids
actions$user_id = actions %>% group_indices(user_id)

# Relevel the age group factor to remove unused values
actions$age_group = droplevels(actions$age_group)
```
```{r, message=FALSE, warning=FALSE}
# Helper functions copied from http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/

## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    # library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

powerTransform <- function(y, lambda1, lambda2 = NULL, method = "boxcox") {

  boxcoxTrans <- function(x, lam1, lam2 = NULL) {
    # if we set lambda2 to zero, it becomes the one parameter transformation
    lam2 <- ifelse(is.null(lam2), 0, lam2)
  
    if (lam1 == 0L) {
      log(y + lam2)
    } else {
      (((y + lam2)^lam1) - 1) / lam1
    }
  }

  switch(method
  , boxcox = boxcoxTrans(y, lambda1, lambda2)
  , tukey = y^lambda1
  )
}

# Function for computing the predictions and CIs for the conditional probability
predictCIsLogistic <- function(object, newdata, level = 0.95) {
  # Compute predictions in the log-odds
  pred <- predict(object = object, newdata = newdata, se.fit = TRUE)

  # CI in the log-odds
  za <- qnorm(p = (1 - level) / 2)
  lwr <- pred$fit + za * pred$se.fit
  upr <- pred$fit - za * pred$se.fit

  # Transform to probabilities
  fit <- 1 / (1 + exp(-pred$fit))
  lwr <- 1 / (1 + exp(-lwr))
  upr <- 1 / (1 + exp(-upr))

  # Return a matrix with column names "fit", "lwr" and "upr"
  result <- cbind(fit, lwr, upr)
  colnames(result) <- c("fit", "lwr", "upr")
  return(result)
}

# -loglik(beta)
minusLogLik <- function(beta) {
  p <- 1 / (1 + exp(-(beta[1] + beta[2] * x)))
  -sum(y1 * log(p) + (1 - y1) * log(1 - p))
}

# Plotting function
plotFunGLM <- function(x, eta, y, n = 200, ind = 1, fam = "poisson") {
  
  if (missing(y)) {
    y <- switch(fam,
                "poisson" = rpois(n, lambda = exp(eta)),
                "binomial" = rbinom(n, prob = 1 / (1 + exp(-eta)), size = 1))
  }
  mod <- glm(y ~ x, family = fam)
  if (ind < 7) {
    plot(mod, which = ind,
         main = list("Residuals vs Fitted", "Normal Q-Q", "Scale-Location", 
                     "Cook's distance", "Residuals vs Leverage", 
                     expression("Cook's dist vs Leverage  " 
                                * h[ii]/(1 - h[ii])))[ind], caption = "")
  } else {
    plot(mod$residuals, type = "o", ylab = "Residuals", 
         main = "Residuals series")
  }
  plot(x, y, pch = 16, main = "Data scatterplot")
  t <- seq(-100, 100, l = 1e4)
  lines(t, predict(mod, newdata = data.frame(x = t), type = "response"), 
        col = 2)
  
}

# Computation of the R^2 with a function -- useful for repetitive computations
r2glm <- function(model) {
  summaryLog <- summary(model)
  1 - summaryLog$deviance / summaryLog$null.deviance
}

# Save a model
saveModel = function(model, folder = data_folder) {
  saveRDS(model, file = file.path(folder, paste(substitute(model), ".RDS", sep = '')))
}

# Load a model
loadModel = function(model_name, folder = data_folder) {
  return(readRDS(file.path(folder, paste(model_name, '.RDS', sep = ''))))
}
```

## User Level Metrics {.tabset}

### Scenario Completed?

We assume the following structural model

```
scenario_completed ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal
```

We use the family of Binomial models based on the results in the other notebook where we focused on finding the right distribution for the data.

```{r}
plot_df = users;
```
```{r, eval=train_models}
scenario_completed.model = glm(
  scenario_completed ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal,
  data = plot_df,
  family = binomial()
)
saveModel(scenario_completed.model)
```
```{r, eval=!train_models}
scenario_completed.model = loadModel("scenario_completed.model")
```
```{r}
print(with(scenario_completed.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(scenario_completed.model))
```

Based on the data, only the effect of the ax variable matters

```{r, eval=train_models}
scenario_completed.model.sparse = glm(
  scenario_completed ~ has_ax,
  data = plot_df,
  family = binomial()
)
saveModel(scenario_completed.model.sparse)
```
```{r, eval=!train_models}
scenario_completed.model.sparse = loadModel("scenario_completed.model.sparse")
```
```{r}
print(with(scenario_completed.model.sparse, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(scenario_completed.model.sparse))
```

So now, we can plot the effects:

```{r}
plot_summs(scenario_completed.model, scenario_completed.model.sparse,
           omit.coefs = c("age_group.L", "age_group.Q", "age_group.C", "age_group^4",
                          "age_group^5", "age_group^6", "age_group^7", "(Intercept)"))
plot_summs(scenario_completed.model.sparse, omit.coefs = NULL, plot.distributions = T)
ggPredict(scenario_completed.model.sparse, se = T)
```

Then plot the data itself:

```{r}
gg_df = plot_df
gg_df$study_condition = factor(plot_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
gg_df$scenario_completed = factor(plot_df$scenario_completed)
levels(gg_df$scenario_completed) = c("incomplete", "complete")
ggplot(gg_df %>% count(study_condition, scenario_completed),
       aes(study_condition, n, fill=scenario_completed)) +
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle = 45))
```
```{r, message=F, warning=F}
rm(scenario_completed.model)
rm(scenario_completed.model.sparse)
gc()
```


### Num Actions Diff {.tabset}

We assume a structural model where we remove the effect that the action suggestions might have on the number of actions over the number of optimal actions taken by using the prediction of action completion based on the action suggestions

```
num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal
# Optionally
num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal + scenario_completed
```

We use a negative binomial distribution to estimate the params, based on tests in the other notebook. First, let's examine without a control for scenario completed.

#### Naive Model

```{r}
plot_df = users;
plot_df$scenario_completed = factor(plot_df$scenario_completed)
```
```{r, eval=train_models}
actions_diff.model = glm.nb(
  num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal,
  data = plot_df
)
saveModel(actions_diff.model)
```
```{r, eval=!train_models}
actions_diff.model = loadModel("actions_diff.model")
```
```{r}
print(with(actions_diff.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model))
```

There is a high effect of robot experience and of action suggestions. How does a reduced model fare?

```{r, eval=train_models}
actions_diff.model.sparse = glm.nb(
  num_actions_diff ~ robot_experience + has_ax,
  data = plot_df
)
saveModel(actions_diff.model.sparse)
```
```{r, eval=!train_models}
actions_diff.model.sparse = loadModel("actions_diff.model.sparse")
```
```{r}
print(with(actions_diff.model.sparse, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model.sparse))

# Also show comparisons (remove the age factors because there's massive variation in those)
# Turns out that we can't plot the non-sparse model for some reason.
# plot_summs(actions_diff.model, actions_diff.model.sparse,
#            omit.coefs = c("age_group.L", "age_group.Q", "age_group.C", "age_group^4",
#                           "age_group^5", "age_group^6", "age_group^7", "(Intercept)"))
plot_summs(actions_diff.model.sparse, omit.coefs = NULL, plot.distributions = T)
# Cannot plot binomial responses?
plot_df$fitted = actions_diff.model.sparse$fitted.values
ggplot(plot_df, aes(x = robot_experience, y = num_actions_diff, color = has_ax, fill = has_ax)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter() +
  geom_line(aes(y = fitted, x = robot_experience, color = has_ax, group = has_ax, size = 2))
```

Unfortunately, while AIC is lower, the R^2 has also gone lower. Let's look at the data.

```{r}
gg_df = plot_df
gg_df$study_condition = factor(plot_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
ggplot(gg_df, aes(x = study_condition, y = num_actions_diff, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))

# Normalize by the number of optimal actions...?
ggplot(gg_df, aes(x = study_condition, y = frac_actions_diff, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))
```

So according to the second plot, there is a significant difference of whether a participant completed the scenario or not (fraction of people at max is its own distribution). So we're going to add that as a factor


#### Augmented Model

This time, we plot the data first:

```{r}
gg_df = subset(plot_df, scenario_completed == "1")
gg_df$study_condition = factor(gg_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
ggplot(gg_df, aes(x = study_condition, y = num_actions_diff, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))
```

```{r}
plot_df = users;
plot_df$scenario_completed = factor(plot_df$scenario_completed)
```
```{r, eval=train_models}
actions_diff.model.augmented = glm.nb(
  num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal + scenario_completed,
  data = plot_df
)
saveModel(actions_diff.model.augmented)
```
```{r, eval=!train_models}
actions_diff.model.augmented = loadModel("actions_diff.model.augmented")
```
```{r}
print(with(actions_diff.model.augmented, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model.augmented))
```

There is indeed a large effect of the scenario completed; and controlling for it seems to negate the effect of whether action suggestions are present. Creating the sparser model from this full(er) model based on the factors that are deemed significant

```{r, eval=train_models}
actions_diff.model.augmented.sparse = glm.nb(
  num_actions_diff ~ gender + robot_experience + scenario_completed + has_dx*noise_level,
  data = plot_df
)
saveModel(actions_diff.model.augmented.sparse)
```
```{r, eval=!train_models}
actions_diff.model.augmented.sparse = loadModel("actions_diff.model.augmented.sparse")
```
```{r}
print(with(actions_diff.model.augmented.sparse, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model.augmented.sparse))

# Plot the coefficients. For some unknown reason, we cannot plot this model either
plot_summs(actions_diff.model.augmented.sparse, plot.distributions = T)

# Plot the DX and noise fit
plot_df$fitted = actions_diff.model.augmented.sparse$fitted.values
plot_df$scenario_completed = factor(plot_df$scenario_completed)
ggplot(plot_df, aes(x = gender, y = num_actions_diff, color = scenario_completed, fill = scenario_completed)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter() +
  geom_line(aes(y = fitted, x = gender, color = scenario_completed, group = scenario_completed, size = 2))
```

```{r, message=F, warning=F}
rm(actions_diff.model, actions_diff.model.sparse, actions_diff.model.augmented, actions_diff.model.augmented.sparse)
gc()
```


## Action Level Metrics {.tabset}

### Taking Optimal Actions

One can almost think of this as an inverse of the "reliance" metric mentioned by Jessie Yang et al. We're going to need brms to fit all the models here.

```{r}
gg_df = users
gg_df$study_condition = factor(gg_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
ggplot(gg_df, aes(x = study_condition, y = num_ax_optimal, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  # geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))

# This is technically what the binomial regression is checking
ggplot(gg_df, aes(x = study_condition, y = frac_ax_optimal, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  # geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))
```

The choice of the model family is informed by the tests in the second markdown file.

```{r}
plot_df = actions
```
```{r, eval=train_models}
# Fit the main model
optimal_action.model = brm(
  optimal_ax | trials(num_actions) ~ ((has_dx + has_ax) * noise_level) + (age_group + robot_experience + gender) + state_idx + (1 | user_id),
  data = plot_df,
  family = "binomial",
  cores = 4
)
optimal_action.model = add_criterion(optimal_action.model, "waic")
optimal_action.model = add_criterion(optimal_action.model, "loo")
saveModel(optimal_action.model)
```
```{r, eval=!train_models}
optimal_action.model = loadModel("optimal_action.model")
```
```{r}
print(summary(optimal_action.model))
print(optimal_action.model$criteria$loo$estimates)
```

```{r}
# Plot the effects of the condition (the stuff we care about)
hyp_to_test = c("has_axTRUE = 0", "has_dxTRUE = 0",
                "noise_level.Q = 0", "noise_level.L = 0",
                "has_axTRUE:noise_level.Q = 0", "has_axTRUE:noise_level.L = 0",
                "has_dxTRUE:noise_level.Q = 0", "has_dxTRUE:noise_level.L = 0")
hyp_results = hypothesis(optimal_action.model, hypothesis = hyp_to_test)
print(as.matrix(hyp_results$hypothesis))
plot(hyp_results, ask = F)

mcmc_areas(as.matrix(optimal_action.model), regex_pars = "has_|noise_", prob = 0.95, prob_outer = 1)
mcmc_intervals(as.matrix(optimal_action.model), regex_pars = "b_", prob = 0.90, prob_outer = 0.95)
```

Based on the plots, it seems that a reduced model for this model might include state_idx, robot_experience, age_group, and has_ax.

```{r, eval=train_models}
optimal_action.model.sparse = brm(
  optimal_ax | trials(num_actions) ~ has_ax + age_group + robot_experience + state_idx + (1 | user_id),
  data = plot_df,
  family = "binomial",
  cores = 4,
)
optimal_action.model.sparse = add_criterion(optimal_action.model.sparse, "waic")
optimal_action.model.sparse = add_criterion(optimal_action.model.sparse, "loo")
saveModel(optimal_action.model.sparse)
```
```{r, eval=!train_models}
optimal_action.model.sparse = loadModel("optimal_action.model.sparse")
```
```{r}
print(summary(optimal_action.model.sparse))
print(optimal_action.model.sparse$criteria$loo$estimates)
print(loo_compare(optimal_action.model, optimal_action.model.sparse))

# Plot the effects of the condition (the stuff we care about)
hyp_to_test = c("has_axTRUE = 0")
hyp_results = hypothesis(optimal_action.model.sparse, hypothesis = hyp_to_test)
print(as.matrix(hyp_results$hypothesis))
plot(hyp_results, ask = F)

mcmc_areas(as.matrix(optimal_action.model.sparse), regex_pars = "has_|noise_", prob = 0.95, prob_outer = 1)
mcmc_intervals(as.matrix(optimal_action.model.sparse), regex_pars = "b_", prob = 0.90, prob_outer = 0.95)
```

So there are three independent effects; get the conditional plots for those

```{r}
plot(conditional_effects(optimal_action.model.sparse, effects = "has_ax"), ask = F, points = T)
plot(conditional_effects(optimal_action.model.sparse, effects = "robot_experience"), ask = F, points = T)
plot(conditional_effects(optimal_action.model.sparse, effects = "age_group"), ask = F, points = T)
```
```{r}
# We want to create our own conditional sample, but don't want to kill our machine
plot_df$state_idx = mean(plot_df$state_idx)
g = subset(plot_df, age_group == 0 | age_group == 8) %>%
  data_grid(num_actions, has_ax, age_group, robot_experience, state_idx, user_id)
fits = g %>% add_fitted_draws(optimal_action.model.sparse, n=10)
preds = g %>% add_predicted_draws(optimal_action.model.sparse, n=10)

# Binary responses are obvious
plot_df %>%
  ggplot(aes(y = has_ax, x = optimal_ax / num_actions)) +
  stat_halfeyeh(aes(x = .value / num_actions), position = position_nudge(y = 0.1), data = fits) +
  stat_intervalh(aes(x = .prediction / num_actions), data = preds) +
  geom_point(data = plot_df, color = 'gray')

# For multi-level responses, we should do a pairwise comparison
plot_df %>%
  ggplot(aes(y = robot_experience, x = optimal_ax / num_actions)) +
  stat_halfeyeh(aes(x = .value / num_actions), position = position_nudge(y = 0.1), data = fits) +
  stat_intervalh(aes(x = .prediction / num_actions), data = preds) +
  geom_point(data = plot_df, color = 'gray')

# I don't understand why there are more than 2 age groups... is it because of the sampling process?
plot_df %>%
  ggplot(aes(y = age_group, x = optimal_ax / num_actions)) +
  stat_halfeyeh(aes(x = .value / num_actions), position = position_nudge(y = 0.1), data = fits) +
  stat_intervalh(aes(x = .prediction / num_actions), data = preds) +
  geom_point(data = plot_df, color = 'gray')
```

```{r, message=F, warning=F}
rm(optimal_action.model, optimal_action.model.sparse)
gc()
```


### Following Suggestions of Actions


```{r}
gg_df = subset(users, has_ax)
gg_df$study_condition = factor(gg_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
ggplot(gg_df, aes(x = study_condition, y = num_ax_followed, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  # geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))

# This is technically what the binomial regression is checking
ggplot(gg_df, aes(x = study_condition, y = frac_ax_followed, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  # geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))
```

The choice of the model family is informed by the tests in the second markdown file.

```{r}
plot_df = subset(actions, has_ax)
```
```{r, eval=train_models}
# Fit the main model
follow_action.model = brm(
  chose_ax | trials(num_actions) ~ (has_dx * noise_level) + (age_group + robot_experience + gender) + state_idx + (1 | user_id),
  data = plot_df,
  family = "binomial",
  cores = 4
)
follow_action.model = add_criterion(follow_action.model, "waic")
follow_action.model = add_criterion(follow_action.model, "loo")
saveModel(follow_action.model)
```
```{r, eval=!train_models}
follow_action.model = loadModel("follow_action.model")
```
```{r}
print(summary(follow_action.model))
print(follow_action.model$criteria$loo$estimates)
```

```{r}
# Plot the effects of the condition (the stuff we care about)
hyp_to_test = c("has_dxTRUE = 0",
                "noise_level.Q = 0", "noise_level.L = 0",
                "has_dxTRUE:noise_level.Q = 0", "has_dxTRUE:noise_level.L = 0")
hyp_results = hypothesis(follow_action.model, hypothesis = hyp_to_test)
print(as.matrix(hyp_results$hypothesis))
plot(hyp_results, ask = F)

mcmc_areas(as.matrix(follow_action.model), regex_pars = "has_|noise_", prob = 0.95, prob_outer = 1)
mcmc_intervals(as.matrix(follow_action.model), regex_pars = "b_", prob = 0.90, prob_outer = 0.95)
```

Based on the plots, it seems that a reduced model for this model might include state_idx, robot_experience, age_group, and gender

```{r, eval=train_models}
follow_action.model.sparse = brm(
  chose_ax | trials(num_actions) ~ gender + age_group + robot_experience + state_idx + (1 | user_id),
  data = plot_df,
  family = "binomial",
  cores = 4,
)
follow_action.model.sparse = add_criterion(follow_action.model.sparse, "waic")
follow_action.model.sparse = add_criterion(follow_action.model.sparse, "loo")
saveModel(follow_action.model.sparse)
```
```{r, eval=!train_models}
follow_action.model.sparse = loadModel("follow_action.model.sparse")
```
```{r}
print(summary(follow_action.model.sparse))
print(follow_action.model.sparse$criteria$loo$estimates)
print(loo_compare(follow_action.model, follow_action.model.sparse))

# Our IV is not part of this condition
# hyp_to_test = c("has_axTRUE = 0")
# hyp_results = hypothesis(follow_action.model.sparse, hypothesis = hyp_to_test)
# print(as.matrix(hyp_results$hypothesis))
# plot(hyp_results, ask = F)

# mcmc_areas(as.matrix(follow_action.model.sparse), regex_pars = "has_|noise_", prob = 0.95, prob_outer = 1)
mcmc_intervals(as.matrix(follow_action.model.sparse), regex_pars = "b_", prob = 0.90, prob_outer = 0.95)
```

So there are three independent effects; get the conditional plots for those

```{r}
plot(conditional_effects(follow_action.model.sparse, effects = "gender"), ask = F, points = T)
plot(conditional_effects(follow_action.model.sparse, effects = "robot_experience"), ask = F, points = T)
plot(conditional_effects(follow_action.model.sparse, effects = "age_group"), ask = F, points = T)
```
```{r}
# We want to create our own conditional sample, but don't want to kill our machine
plot_df$state_idx = mean(plot_df$state_idx)
g = subset(plot_df, age_group == 0 | age_group == 8) %>%
  data_grid(num_actions, gender, age_group, robot_experience, state_idx, user_id)
fits = g %>% add_fitted_draws(follow_action.model.sparse, n=10)
preds = g %>% add_predicted_draws(follow_action.model.sparse, n=10)

# Binary responses are obvious
plot_df %>%
  ggplot(aes(y = gender, x = chose_ax / num_actions)) +
  stat_halfeyeh(aes(x = .value / num_actions), position = position_nudge(y = 0.1), data = fits) +
  stat_intervalh(aes(x = .prediction / num_actions), data = preds) +
  geom_point(data = plot_df, color = 'gray')

# For multi-level responses, we should do a pairwise comparison
plot_df %>%
  ggplot(aes(y = robot_experience, x = chose_ax / num_actions)) +
  stat_halfeyeh(aes(x = .value / num_actions), position = position_nudge(y = 0.1), data = fits) +
  stat_intervalh(aes(x = .prediction / num_actions), data = preds) +
  geom_point(data = plot_df, color = 'gray')

# I don't understand why there are more than 2 age groups... is it because of the sampling process?
plot_df %>%
  ggplot(aes(y = age_group, x = chose_ax / num_actions)) +
  stat_halfeyeh(aes(x = .value / num_actions), position = position_nudge(y = 0.1), data = fits) +
  stat_intervalh(aes(x = .prediction / num_actions), data = preds) +
  geom_point(data = plot_df, color = 'gray')
```

```{r, message=F, warning=F}
rm(follow_action.model, follow_action.model.sparse)
gc()
```
