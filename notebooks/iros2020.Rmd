---
title: "IROS 2020"
output:
  html_document:
    theme: readable
    code_folding: hide
    df_print: kable
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r message=FALSE, warning=FALSE}
library(readr)
library(ggplot2)
library(broom)
library(reshape)
library(car)
library(interplot)
library(multcomp)
library(pastecs)
library(nlme)
library(stats)
library(plyr)
library(ggsignif)
library(PMCMR)
library(lmtest)
library(lme4)
library(dplyr)
library(brms)
library(jtools)
library(ggiraph)
library(ggiraphExtra)
```
```{r, message=FALSE, warning=FALSE}
# Load the CSV files
users = read_csv(
  "~/Documents/GT/Research/Data/arbitration/2019-12-09/results/users.csv",
  col_types = cols(
    study_condition = col_factor(),
    noise_level = col_factor(ordered = T),
    age_group = col_factor(levels = seq(from = 0, to = 8), ordered = T),
    robot_experience = col_factor(levels = seq(from = 0, to = 4), ordered = T)
  )
)

actions = read_csv(
  "~/Documents/GT/Research/Data/arbitration/2019-12-09/results/actions.csv",
  col_types = cols(
    study_condition = col_factor(),
    noise_level = col_factor(ordered = T),
    age_group = col_factor(levels = seq(from = 0, to = 8), ordered = T),
    robot_experience = col_factor(levels = seq(from = 0, to = 4), ordered = T)
  )
)

# Relabel the factors
users$study_condition = mapvalues(users$study_condition,
                                  from = seq(from = 1, to = 10),
                                  to = c("1"="BASELINE",
                                         "2"="DX_100", "3"="AX_100", "4"="DXAX_100",
                                         "5"="DX_90", "6"="AX_90", "7"="DXAX_90",
                                         "8"="DX_80", "9"="AX_80", "10"="DXAX_80"))
actions$study_condition = mapvalues(actions$study_condition,
                                    from = seq(from = 1, to = 10),
                                    to = c("1"="BASELINE",
                                           "2"="DX_100", "3"="AX_100", "4"="DXAX_100",
                                           "5"="DX_90", "6"="AX_90", "7"="DXAX_90",
                                           "8"="DX_80", "9"="AX_80", "10"="DXAX_80"))

# # Relevel the non-binary age
users$gender[users$gender == 'U'] = 'M'
actions$gender[actions$gender == 'U'] = 'M'

# Change binary responses to integers
users$scenario_completed = as.integer(users$scenario_completed)
actions$scenario_completed = as.integer(actions$scenario_completed)

actions$optimal_ax = as.integer(actions$optimal_ax)
actions$chose_ax = as.integer(actions$chose_ax)

actions$optimal_dx = as.integer(actions$optimal_dx)
actions$chose_dx = as.integer(actions$optimal_dx)

# Relabel user ids
actions$user_id = actions %>% group_indices(user_id)
```
```{r, message=FALSE, warning=FALSE}
# Helper functions copied from http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/

## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    # library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

powerTransform <- function(y, lambda1, lambda2 = NULL, method = "boxcox") {

  boxcoxTrans <- function(x, lam1, lam2 = NULL) {
    # if we set lambda2 to zero, it becomes the one parameter transformation
    lam2 <- ifelse(is.null(lam2), 0, lam2)
  
    if (lam1 == 0L) {
      log(y + lam2)
    } else {
      (((y + lam2)^lam1) - 1) / lam1
    }
  }

  switch(method
  , boxcox = boxcoxTrans(y, lambda1, lambda2)
  , tukey = y^lambda1
  )
}

# Function for computing the predictions and CIs for the conditional probability
predictCIsLogistic <- function(object, newdata, level = 0.95) {
  # Compute predictions in the log-odds
  pred <- predict(object = object, newdata = newdata, se.fit = TRUE)

  # CI in the log-odds
  za <- qnorm(p = (1 - level) / 2)
  lwr <- pred$fit + za * pred$se.fit
  upr <- pred$fit - za * pred$se.fit

  # Transform to probabilities
  fit <- 1 / (1 + exp(-pred$fit))
  lwr <- 1 / (1 + exp(-lwr))
  upr <- 1 / (1 + exp(-upr))

  # Return a matrix with column names "fit", "lwr" and "upr"
  result <- cbind(fit, lwr, upr)
  colnames(result) <- c("fit", "lwr", "upr")
  return(result)
}

# -loglik(beta)
minusLogLik <- function(beta) {
  p <- 1 / (1 + exp(-(beta[1] + beta[2] * x)))
  -sum(y1 * log(p) + (1 - y1) * log(1 - p))
}

# Plotting function
plotFunGLM <- function(x, eta, y, n = 200, ind = 1, fam = "poisson") {
  
  if (missing(y)) {
    y <- switch(fam,
                "poisson" = rpois(n, lambda = exp(eta)),
                "binomial" = rbinom(n, prob = 1 / (1 + exp(-eta)), size = 1))
  }
  mod <- glm(y ~ x, family = fam)
  if (ind < 7) {
    plot(mod, which = ind,
         main = list("Residuals vs Fitted", "Normal Q-Q", "Scale-Location", 
                     "Cook's distance", "Residuals vs Leverage", 
                     expression("Cook's dist vs Leverage  " 
                                * h[ii]/(1 - h[ii])))[ind], caption = "")
  } else {
    plot(mod$residuals, type = "o", ylab = "Residuals", 
         main = "Residuals series")
  }
  plot(x, y, pch = 16, main = "Data scatterplot")
  t <- seq(-100, 100, l = 1e4)
  lines(t, predict(mod, newdata = data.frame(x = t), type = "response"), 
        col = 2)
  
}


# Computation of the R^2 with a function -- useful for repetitive computations
r2glm <- function(model) {

  summaryLog <- summary(model)
  1 - summaryLog$deviance / summaryLog$null.deviance

}
```

## User Level Metrics {.tabset}

### Scenario Completed?

We assume the following structural model

```
scenario_completed ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal
```

We use the family of Binomial models based on the results in the other notebook where we focused on finding the right distribution for the data.

```{r}
plot_df = users;
scenario_completed.model = glm(
  scenario_completed ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal,
  data = plot_df,
  family = binomial()
)
print(with(scenario_completed.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(scenario_completed.model))
```

Based on the data, only the effect of the ax and noise variables matters

```{r}
scenario_completed.model.sparse = glm(
  scenario_completed ~ has_ax + noise_level,
  data = plot_df,
  family = binomial()
)
print(with(scenario_completed.model.sparse, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(scenario_completed.model.sparse))
```

So now, we can plot the effects:

```{r}
plot_summs(scenario_completed.model, scenario_completed.model.sparse,
           omit.coefs = c("age_group.L", "age_group.Q", "age_group.C", "age_group^4",
                          "age_group^5", "age_group^6", "age_group^7", "(Intercept)"))
plot_summs(scenario_completed.model.sparse, omit.coefs = NULL, plot.distributions = T)
ggPredict(scenario_completed.model.sparse, se = T)
```

Then plot the data itself:

```{r}
gg_df = plot_df
gg_df$study_condition = factor(plot_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
gg_df$scenario_completed = factor(plot_df$scenario_completed)
levels(gg_df$scenario_completed) = c("incomplete", "complete")
ggplot(gg_df %>% count(study_condition, scenario_completed),
       aes(study_condition, n, fill=scenario_completed)) +
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle = 45))
```


### Num Actions Diff {.tabset}

We assume a structural model where we remove the effect that the action suggestions might have on the number of actions over the number of optimal actions taken by using the prediction of action completion based on the action suggestions

```
num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal
# Optionally
num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal + scenario_completed
```

We use a negative binomial distribution to estimate the params, based on tests in the other notebook. First, let's examine without a control for scenario completed.

#### Naive Model

```{r}
plot_df = users;
plot_df$scenario_completed = factor(plot_df$scenario_completed)
actions_diff.model = glm.nb(
  num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal,
  data = plot_df
)
print(with(actions_diff.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model))
```

There is a high effect of robot experience and of action suggestions. How does a reduced model fare?

```{r}
actions_diff.model.sparse = glm.nb(
  num_actions_diff ~ has_ax + robot_experience,
  data = plot_df
)
print(with(actions_diff.model.sparse, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model.sparse))

# Also show comparisons (remove the age factors because there's massive variation in those)
# Turns out that we can't plot the non-sparse model for some reason.
# plot_summs(actions_diff.model, actions_diff.model.sparse,
#            omit.coefs = c("age_group.L", "age_group.Q", "age_group.C", "age_group^4",
#                           "age_group^5", "age_group^6", "age_group^7", "(Intercept)"))
plot_summs(actions_diff.model.sparse, omit.coefs = NULL, plot.distributions = T)
# Cannot plot binomial responses?
# ggPredict(actions_diff.model.sparse)
```

Unfortunately, while AIC is lower, the R^2 has also gone lower. Let's look at the data.

```{r}
gg_df = plot_df
gg_df$study_condition = factor(plot_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
ggplot(gg_df, aes(x = study_condition, y = num_actions_diff, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))

# Normalize by the number of optimal actions...?
ggplot(gg_df, aes(x = study_condition, y = frac_actions_diff, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))
```

So according to the second plot, there is a significant difference of whether a participant completed the scenario or not (fraction of people at max is its own distribution). So we're going to add that as a factor


#### Augmented Model

This time, we plot the data first:

```{r}
gg_df = subset(plot_df, scenario_completed == "1")
gg_df$study_condition = factor(gg_df$study_condition, levels = c("DX_100", "AX_100", "DXAX_100", "DX_90", "AX_90", "DXAX_90", "DX_80", "AX_80", "DXAX_80", "BASELINE"))
ggplot(gg_df, aes(x = study_condition, y = num_actions_diff, fill = noise_level)) +
  geom_boxplot(aes(alpha = 0.3)) +
  geom_jitter(aes(color = noise_level)) +
  theme(axis.text.x = element_text(angle = 45))
```

```{r}
plot_df = users;
plot_df$scenario_completed = factor(plot_df$scenario_completed)
actions_diff.model.augmented = glm.nb(
  num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal + scenario_completed,
  data = plot_df
)
print(with(actions_diff.model.augmented, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model.augmented))
```

There is indeed a large effect of the scenario completed; and controlling for it seems to negate the effect of whether action suggestions are present. Creating the sparser model from this full(er) model based on the factors that are deemed significant

```{r}
actions_diff.model.augment.sparse = glm.nb(
  num_actions_diff ~ gender + robot_experience + scenario_completed + has_dx:noise_level,
  data = plot_df
)
print(with(actions_diff.model.augment.sparse, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)))
print(summ(actions_diff.model.augment.sparse))

# Plot the coefficients. For some unknown reason, we cannot plot this model either
# plot_summs(actions_diff.model.augment.sparse, omit.coefs = c("has_dxTRUE:noise_level2.0", "(Intercept)"))
```


## Action Level Metrics {.tabset}

### Number of Optimal Actions

One can almost think of this as an inverse of the "reliance" metric mentioned by Jessie Yang et al.

