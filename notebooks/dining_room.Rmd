---
title: "AMT Effects of Suggestions"
output:
  html_document:
    theme: readable
    code_folding: hide
    df_print: kable
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r, message=FALSE, warning=FALSE}
library(readr)
library(ggplot2)
library(reshape)
library(car)
library(compute.es)
library(multcomp)
library(pastecs)
library(nlme)
library(stats)
library(plyr)
library(ez)
library(ggsignif)
library(pgirmess)
library(PMCMR)
library(Exact)
library(psych)
library(gvlma)
library(lmtest)
library(lme4)
library(fitdistrplus)
library(dplyr)
library(brms)
```
```{r, message=FALSE, warning=FALSE}
# Load the CSV files
users = read_csv(
  "~/Documents/GT/Research/Data/arbitration/2019-12-09/results/users.csv",
  col_types = cols(
    study_condition = col_factor(),
    noise_level = col_factor(),
    age_group = col_factor(),
    robot_experience = col_factor()
  )
)

actions = read_csv(
  "~/Documents/GT/Research/Data/arbitration/2019-12-09/results/actions.csv",
  col_types = cols(
    study_condition = col_factor(),
    noise_level = col_factor(),
    age_group = col_factor(),
    robot_experience = col_factor()
  )
)

# Relabel the factors
users$study_condition = mapvalues(users$study_condition,
                                  from = seq(from = 1, to = 10),
                                  to = c("1"="BASELINE",
                                         "2"="DX_100", "3"="AX_100", "4"="DXAX_100",
                                         "5"="DX_90", "6"="AX_90", "7"="DXAX_90",
                                         "8"="DX_80", "9"="AX_80", "10"="DXAX_80"))
actions$study_condition = mapvalues(actions$study_condition,
                                    from = seq(from = 1, to = 10),
                                    to = c("1"="BASELINE",
                                          "2"="DX_100", "3"="AX_100", "4"="DXAX_100",
                                          "5"="DX_90", "6"="AX_90", "7"="DXAX_90",
                                          "8"="DX_80", "9"="AX_80", "10"="DXAX_80"))

# Relevel the non-binary age
users$gender[users$gender == 'U'] = 'M'
actions$gender[actions$gender == 'U'] = 'M'

# Change scenario completed to an integer
users$scenario_completed = as.integer(users$scenario_completed)
```
```{r, message=FALSE, warning=FALSE}
# Helper functions copied from http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/

## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    # library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

powerTransform <- function(y, lambda1, lambda2 = NULL, method = "boxcox") {

  boxcoxTrans <- function(x, lam1, lam2 = NULL) {
    # if we set lambda2 to zero, it becomes the one parameter transformation
    lam2 <- ifelse(is.null(lam2), 0, lam2)
  
    if (lam1 == 0L) {
      log(y + lam2)
    } else {
      (((y + lam2)^lam1) - 1) / lam1
    }
  }

  switch(method
  , boxcox = boxcoxTrans(y, lambda1, lambda2)
  , tukey = y^lambda1
  )
}

# Function for computing the predictions and CIs for the conditional probability
predictCIsLogistic <- function(object, newdata, level = 0.95) {
  # Compute predictions in the log-odds
  pred <- predict(object = object, newdata = newdata, se.fit = TRUE)

  # CI in the log-odds
  za <- qnorm(p = (1 - level) / 2)
  lwr <- pred$fit + za * pred$se.fit
  upr <- pred$fit - za * pred$se.fit

  # Transform to probabilities
  fit <- 1 / (1 + exp(-pred$fit))
  lwr <- 1 / (1 + exp(-lwr))
  upr <- 1 / (1 + exp(-upr))

  # Return a matrix with column names "fit", "lwr" and "upr"
  result <- cbind(fit, lwr, upr)
  colnames(result) <- c("fit", "lwr", "upr")
  return(result)
}

# -loglik(beta)
minusLogLik <- function(beta) {
  p <- 1 / (1 + exp(-(beta[1] + beta[2] * x)))
  -sum(y1 * log(p) + (1 - y1) * log(1 - p))
}

# Plotting function
plotFunGLM <- function(x, eta, y, n = 200, ind = 1, fam = "poisson") {
  
  if (missing(y)) {
    y <- switch(fam,
                "poisson" = rpois(n, lambda = exp(eta)),
                "binomial" = rbinom(n, prob = 1 / (1 + exp(-eta)), size = 1))
  }
  mod <- glm(y ~ x, family = fam)
  if (ind < 7) {
    plot(mod, which = ind,
         main = list("Residuals vs Fitted", "Normal Q-Q", "Scale-Location", 
                     "Cook's distance", "Residuals vs Leverage", 
                     expression("Cook's dist vs Leverage  " 
                                * h[ii]/(1 - h[ii])))[ind], caption = "")
  } else {
    plot(mod$residuals, type = "o", ylab = "Residuals", 
         main = "Residuals series")
  }
  plot(x, y, pch = 16, main = "Data scatterplot")
  t <- seq(-100, 100, l = 1e4)
  lines(t, predict(mod, newdata = data.frame(x = t), type = "response"), 
        col = 2)
  
}


# Computation of the R^2 with a function -- useful for repetitive computations
r2glm <- function(model) {

  summaryLog <- summary(model)
  1 - summaryLog$deviance / summaryLog$null.deviance

}
```

## Metrics

### Scenario Completed

Did the person complete the scenario?

```{r}
plot_df = users;
complete.model = glm(
  scenario_completed ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience),
  data=plot_df,
  family = 'binomial'
)
summary(complete.model)
with(complete.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
```
```{r, eval=FALSE}
# Additional diagnostics
r2glm(complete.model)
anova(complete.model, test = "Chisq")
car::vif(complete.model)
```


### Num Actions Diff

This is the number of actions taken by the user minus the number of optimal actions for the scenario they were provided.

```{r}
plot_df = users;
plot_df$scenario_completed_pred = complete.model$fitted.values
actions_diff.model = glm.nb(
  num_actions_diff ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal + scenario_completed,
  data=plot_df,
)
summary(actions_diff.model)
with(actions_diff.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
```
```{r, eval=FALSE}
# Additional diagnostics
r2glm(actions_diff.model)
anova(actions_diff.model, test = "Chisq")
car::vif(actions_diff.model)
```


### Took Optimal Action

Given the state, did the user take the optimal action?

```{r, eval=FALSE}
# Linear Regression...
plot_df = actions
plot_df$user_id = 
optimal_action.model = lme(
  optimal_ax ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + state_idx,
  random = ~1 | user_id,
  data=plot_df
)
summary(optimal_action.model)
shapiro.test(optimal_action.model$residuals)
```

```{r}
# Logistic regression
plot_df = actions
plot_df$user_id = scale(actions %>% group_indices(user_id))
plot_df$state_idx = scale(plot_df$state_idx)
optimal_action.model = brm(
  optimal_ax ~ ((has_dx + has_ax) * noise_level) + (age_group + robot_experience) + state_idx + (1 | user_id),
  data=plot_df,
  family = 'bernoulli'
)
summary(optimal_action.model)
# with(optimal_action.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
```

```{r, eval=FALSE}
# Additional diagnostics
r2glm(optimal_action.model)
anova(optimal_action.model, test = "Chisq")
# Cannot perform VIF test
# alias(optimal_action.model)
car::vif(optimal_action.model)
```
