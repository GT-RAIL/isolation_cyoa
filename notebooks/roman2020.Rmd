---
title: "RO-MAN 2020"
output:
  html_document:
    # theme: readable
    code_folding: hide
    df_print: tibble
    toc: true
    toc_depth: 4
    number_sections: false
    toc_float: true
    self_contained: false
    lib_dir: roman2020_libs
---

```{r message=FALSE, warning=FALSE}
library(car)
library(stats)
library(grid)
library(gridExtra)
library(fitdistrplus)
# library(dplyr)
# library(forcats)
# library(tibble)
# library(tidyr)
# library(readr)
# library(ggplot2)
# library(stringr)
library(tidyverse)
library(ggsignif)
library(ggthemes)
library(jtools)
library(broom)
library(modelr)
library(loo)
# library(rstanarm)
library(brms)
library(bayesplot)
library(GGally)
library(tidybayes)
library(bayestestR)
library(sjstats)
library(parameters)
library(see)

# Setup for multiprocessing
options(mc.cores = 4)
# library(future)
# plan(multiprocess)

# Make the default coding of contrasts sum-coding; just in case
options(contrasts = c("contr.sum", "contr.poly"))
```

Global options:

```{r}
# Script execution globals
train_models = F     # Retrain the MCMC models. Also infer unknown demographics
plot_posteriors = F  # Plot the posterior distributions (debug)
plot_paper_posteriors = T  # Plot the posterior distributions that are in the paper
plot_diagnostics = T # Plot the diagnostics
report_bayesfactors = F  # Report the Bayes Factor scores of model parameters
default_seed = 0x1331 # For repeatable models and diagnostics
data_folder = "~/Documents/GT/Research/Data/arbitration/2019-12-09/results"
```

Helper functions:

```{r, message=FALSE, warning=FALSE}
# Create a simple coding contrasts matrix
contr.deviation = function(nlevels) {
  x1 = contr.treatment(nlevels)
  x2 = matrix(rep(1/nlevels, (nlevels-1) * nlevels), ncol = (nlevels-1))
  return(x1-x2)
}

# NOTE: For now we're ignoring this advice
# # Use a simple coding contrasts matrix to add our own contrasts columns
# # Explained in: http://talklab.psy.gla.ac.uk/tvw/catpred/
# create_simple_contrasts = function(d, column_name) {
#  factor_column = d %>% pull(column_name)
#  contrast_matrix = contr.deviation(length(levels(factor_column)))
# }

# Save a model
saveModel = function(model, folder = data_folder) {
  saveRDS(model, file = file.path(folder, paste(substitute(model), ".rds", sep = '')))
}

# Load a model
loadModel = function(model_name, folder = data_folder) {
  return(readRDS(file.path(folder, paste(model_name, '.rds', sep = ''))))
}

# Test hypotheses. The NULL arguments need to be provided in this case
test_hypotheses = function(h_df, rope_values = NULL) {
  # Set the default ROPE values
  if (is.null(rope_values)) {
    rope_values = c(-0.1, 0.1)
  }

  pd_test = h_df %>% pd() %>% as_tibble()

  eq_test = h_df %>%
    equivalence_test(range = rope_values, ci = 1.0, verbose = T) %>%
    as_tibble() %>%
    select(Parameter, ROPE_Percentage, ROPE_Equivalence)

  hdi_test = h_df %>% hdi(ci = .89, verbose = T) %>% as_tibble() %>% select(Parameter, CI_low, CI_high)

  point_test = h_df %>%
    point_interval(.width = 0.89, .point = median, .interval = hdi, .simple_names = T) %>%
    select(colnames(h_df)) %>%
    gather(key = "Parameter", value = "Estimate")

  effect_test = point_test %>%
    inner_join(hdi_test, by = "Parameter") %>%
    mutate(Effect_Size = abs(Estimate) * sqrt(3) / pi)
           # There's quite a few nuances that I'm missing with this calculation
           # Effect_CI_low = pmin(abs(CI_low), abs(CI_high)) * sqrt(3) / pi,
           # Effect_CI_high = pmax(abs(CI_low), abs(CI_high)) * sqrt(3) / pi)

  hyp_results = effect_test %>%
    inner_join(pd_test, by = "Parameter") %>%
    inner_join(eq_test, by = "Parameter")

  return(hyp_results)
}

# Fit distributions to vectors and print the results. Also return the fit, if necessary
fit_and_print_dist = function(vec, distr, string, use_mass = F) {
  if (!use_mass) {
    f = fitdist(vec, distr)
  } else {
    f = MASS::fitdistr(vec, distr)
  }
  print(paste(string, f$loglik, f$aic))
  return(f)
}
```

Data loading:

```{r, message=F, warning=F}
# Load the CSV files. If the age_group fill model is run again and we get a different output,
# then remember to update the value here
loadCSV = function(filename, age_group_fill, contrast_func) {
  dat = read_csv(
    file.path(data_folder, filename),
    col_types = cols(
      study_condition = col_factor(),
      suggestion_type = col_factor(levels = c("NONE", "AX", "DX", "DXAX")),
      noise_level = col_factor(ordered = T),
      # gender = col_factor(levels = c("F", "M", "U")),
      # age_group = col_factor(levels = seq(from = 0, to = 8)),  # We don't load this as a factor yet
      robot_experience = col_factor(levels = seq(from = 0, to = 4))
    )
  )

  # Relabel the factors
  dat = dat %>%
    mutate(study_condition = fct_recode(study_condition,
                                        BASELINE="1",
                                        DX_100="2", AX_100="3", DXAX_100="4",
                                        DX_90="5", AX_90="6", DXAX_90="7",
                                        DX_80="8", AX_80="9", DXAX_80="10")) %>%
    mutate(study_condition = fct_relevel(study_condition, c("DX_100", "AX_100", "DXAX_100",
                                                            "DX_90", "AX_90", "DXAX_90",
                                                            "DX_80", "AX_80", "DXAX_80")))

  # Relevel the non-binary gender and make it a factor
  dat = dat %>%
    mutate(gender = ifelse(gender == "U", "M", gender)) %>%
    mutate(gender = factor(gender, levels = c("F", "M")))

  # Change binary responses to integers
  dat = dat %>% mutate(scenario_completed = as.integer(scenario_completed))

  # Relevel age_group and make it a factor
  dat = dat %>%
    mutate(age_group = ifelse(age_group == 0, age_group_fill, age_group)) %>%
    mutate(age_group = factor(age_group, levels = seq(from = 0, to = 8)))

  # Create an unordered noise_level. Also drop unused levels
  dat$age_group = droplevels(dat$age_group)
  dat$gender = droplevels(dat$gender)
  dat$noise_level_f = factor(dat$noise_level, ordered = F)

  # Set the contrasts for everything
  contrasts(dat$age_group) = contrast_func(length(levels(dat$age_group)))
  contrasts(dat$robot_experience) = contrast_func(length(levels(dat$robot_experience)))
  contrasts(dat$gender) = contrast_func(length(levels(dat$gender)))

  contrasts(dat$has_ax) = contrast_func(2)
  contrasts(dat$has_dx) = contrast_func(2)
  contrasts(dat$has_noise) = contrast_func(2)
  contrasts(dat$has_dxax) = contrast_func(2)
  contrasts(dat$has_ax_only) = contrast_func(2)
  contrasts(dat$has_dx_only) = contrast_func(2)
  contrasts(dat$has_suggestions) = contrast_func(2)
  contrasts(dat$suggestion_type) = contr.helmert(4)  # This is a hardcode

  contrasts(dat$noise_level_f) = contrast_func(length(levels(dat$noise_level_f)))

  # Return the data frame
  return(dat)
}

# Get the users df and the actions df
users = loadCSV("users.csv", 4, contr.sum)
actions = loadCSV("actions.csv", 4, contr.sum)

# Change more binary responses to integers
# actions %>%
#   mutate(optimal_ax)
actions = actions %>%
  mutate(optimal_ax = as.integer(optimal_ax),
         chose_ax = as.integer(chose_ax),
         optimal_dx = as.integer(optimal_dx),
         chose_dx = as.integer(chose_dx))

# Relabel user ids to be in the range 1-200. Otherwise, we're using DB ids
# The user ID column in the users table that we can now join on is X1
actions$user_id = actions %>% group_indices(user_id)

# Rescale state ids
actions$state_idx_rescaled = scales::rescale(actions$state_idx)

# Code to relevel the age group factor to remove unused levels. Also, predict the
# value of the 1 unknown age from the other indicators of demographics
# NOTE: If we retrain the model and the output doesn't match the hardcoded
# values, then update those values
if (train_models) {
  plot_df = subset(users, users$age_group != 0)
  plot_df$age_group = factor(plot_df$age_group, levels = seq(from = 0, to = 8), ordered = T)
  plot_df$age_group = droplevels(plot_df$age_group)
  age_group_model = brm(age_group ~ gender + robot_experience, data = plot_df, family = "cumulative")
  data_to_predict = users %>% filter(age_group == 0) %>% select(c("robot_experience", "gender"))
  as_tibble(predict(age_group_model, data_to_predict))
# # A tibble: 1 x 7
#   `P(Y = 2)` `P(Y = 3)` `P(Y = 4)` `P(Y = 5)` `P(Y = 6)` `P(Y = 7)` `P(Y = 8)`
#        <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>
# 1     0.0838      0.202      0.215      0.188      0.110      0.089      0.111
  rm(age_group_model)
}
```

Note that in this notebook, the accuracy variable from the paper is coded as a noise level variable:

|Accuracy   | Noise Level  |
|---|---|
| 100% | 0 |
| 90%  | 1 |
| 80%  | 2 |

Since noise level increases as accuracy decreases, the "sign" of any linear trends observed in the following analyses should be reversed. Everything else stays pretty much the same.

For each of our dependent variables, there are 2 models:

1. With the noise variable as an ordered factor, so that we can make inferences on the trends in the variable
1. With the noise variable as an unordered factor, so that we can make inferences on the values of the variable

We use Deviation / Sum coding in the coding of non-ordered factors so that we can test the influence of individual factor levels over and above the grand mean. We code the suggestion_type as (reverse) Helmert coding so that collinearity between the suggestion condition values is reduced (collinearity invalidates Bayesian hypothesis testing). (The reverse Helmert coding is the default form of helmert coding that's followed in R).

In all our models:

- $\beta_0$ is assumed to be the intercept. In a mixed effects model, this is additionally indexed by $i$, the user; i.e. $\beta_{0i}$.
- $\text{suggestion_type}_i$ which denotes the type of suggestion that the participant received. This factor is coded, using Helmert coding, into three sub-variables (`baseline` is a reference level for this factor):
    - $\text{ax_only}_i$ denotes if sample $i$ received AX suggestions (only) or not
    - $\text{dx_only}_i$ denotes if sample $i$ received DX suggestions (only) or not
    - $\text{dxax}_i$ denotes if sample $i$ received DXAX suggestions or not
- $\text{noise}_i$ denotes the level of noise in the suggestions that sample $i$ received. 0 (100% accuracy) if none was present.
- $\mathbf{X_{demo,i}}$ is a vector of demographic information. For one participant, this information is imputed from a simple linear model of the other participants.
- $\text{no}_i$ denotes the number of optimal actions for the scenario present in sample $i$. This is a proxy for a difficulty rating of the error scenario given to the participant
- $\text{state}_{ij}$ denotes the state the user $i$ visited on action number $j$. The sample, in this case, is indexed by $j$. The states are indexed according to the frequency of users visits (0 = most visited state), and then all the indices are rescaled into the range 0-1.

We test the following hypotheses (the explanations are a statement of the null hypotheses; the coefficients are from the expected regression parameters, given sum/Helmert coding):

- $2\beta_{ax} = 0$: The effect of action suggestions is no better than the baseline condition with no suggestions.
- $3\beta_{dx} + \beta_{ax} = 0$: The effect of diagnosis suggestions is no better than the baseline condition with no suggestions.
- $4\beta_{dxax} + \beta_{ax} + \beta_{dx} = 0$: The effect of both suggestions is no better than the baseline condition with no suggestions.
- $\beta_{noise_L} = 0; \beta_{noise_Q} = 0$: Noise does not have a linear (L) / quadratic (Q) effect on the outcome.

We do not include or test interaction effects in our model because interaction effects add more parameters to our model than can be estimated given the experimental design. Therefore, we assume that noise and the suggestion type have independent effects on each of the outcomes, and comparisons are made against the grand means of all the data.

The method of reporting and testing is based on the following papers:

1. [A protocol for conducting and presenting results of regression‐type analyses](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12577)
1. [Indices of Effect Existence and Significance in the Bayesian Framework](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02767/full). The paper is associated with [this post](https://easystats.github.io/bayestestR/articles/guidelines.html) on how to present results, and [this post](https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html) giving a quick overview of terms (the posts are part of a package I'm using heavily in these analyses)

Note taht we are NOT going to perform model-selection here. Based on what I've read, we're doing confirmatory hypothesis testing, which is not where one should use model selection paradigms.


# FRR: Fault Resolution Rate

**Did the person complete the scenario or not?**

In the code, this variable is called `scenario_completed`.

```{r}
plot_df = users %>%
  select(X1, id, study_condition, start_condition, num_optimal,
         age_group, gender, robot_experience,
         noise_level, noise_level_f, has_noise, suggestion_type,
         has_dx, has_ax, has_ax_only, has_dx_only, has_dxax,
         scenario_completed)

print(summary(plot_df %>%
                mutate(scenario_completed = factor(scenario_completed)) %>%
                select(-X1, -id)
))
```

## Data

```{r fig.height=7, fig.width=15}
# Plot by the study condition
plot_df %>%
  mutate(scenario_completed = factor(scenario_completed)) %>%
  mutate(scenario_completed = fct_recode(scenario_completed, incomplete="0", complete = "1")) %>%
  count(study_condition, scenario_completed) %>%
  ggplot(aes(study_condition, n / 20, fill=scenario_completed)) +
    geom_bar(stat="identity") +
    labs(y = "Fraction completed") +
    scale_fill_economist()

# Plot by suggestion type
gg_df = plot_df %>%
  mutate(scenario_completed = factor(scenario_completed)) %>%
  mutate(scenario_completed = fct_recode(scenario_completed, incomplete="0", complete = "1")) %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  count(suggestion_type, noise_level, scenario_completed)

gg_df %>%
  ggplot(aes(suggestion_type, n/20, fill=scenario_completed)) +
    geom_bar(stat = "identity") +
    facet_grid(cols = vars(noise_level), labeller = label_both) +
    labs(y = "Fraction completed") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

gg_df %>%
  ggplot(aes(noise_level, n/20, fill=scenario_completed)) +
    geom_bar(stat = "identity") +
    facet_grid(cols = vars(suggestion_type)) +
    labs(y = "Fraction completed") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

p1 = gg_df %>%
  filter(scenario_completed == 'complete') %>%
  ggplot(aes(suggestion_type, n/20)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep=":"), size = 2),
               position = position_jitter(width = .2, height = 0)) +
    stat_summary(fun = median, geom="point", shape=23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    legend_none()

p2 = gg_df %>%
  filter(scenario_completed == 'complete') %>%
  ggplot(aes(noise_level, n/20)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep=":"), size = 2),
               position = position_jitter(width = .2, height = 0)) +
    stat_summary(fun = median, geom="point", shape=23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(color = "Type:Noise") +
    theme(legend.position = "right") +
    guides(size = F)

grid.arrange(p1, p2, ncol = 2)
```

## Model

Based on the data, we assume the following structural model:

$$FRR_i = Bernoulli(p_i)$$
$$\begin{aligned}
logit(p_i) &= \beta_0 + \beta_{ax}\text{ax_only}_i + \beta_{dx}\text{dx_only}_i + \beta_{dxax}\text{dxax}_i +\\ &\beta_{noise_L}\text{noise}_i + \beta_{noise_Q}\text{noise}_i +\\
&\beta_{no}\text{no}_i + \mathbf{\beta_{demo}X_{demo,i}}
\end{aligned}$$
$$\beta_{.} \sim Normal(0, 10)$$

Model fitting:

```{r, eval=train_models}
# A null model to compare against
scenario_completed.model.null = brm(
  scenario_completed ~ 0 + Intercept,
  family = "bernoulli",
  prior = set_prior("normal(0, 10)", class = "b"),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
scenario_completed.model.null = add_criterion(scenario_completed.model.null, "waic")
scenario_completed.model.null = add_criterion(scenario_completed.model.null, "loo", reloo = T)
saveModel(scenario_completed.model.null)

# The trend model to see if there is a trend in the noise level variable
scenario_completed.model.t = brm(
  scenario_completed ~ 0 + Intercept + (suggestion_type + noise_level) + (gender + age_group + robot_experience) + num_optimal,
  family = "bernoulli",
  prior = set_prior("normal(0, 10)", class = "b"),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
scenario_completed.model.t = add_criterion(scenario_completed.model.t, "waic")
scenario_completed.model.t = add_criterion(scenario_completed.model.t, "loo", reloo = T)
saveModel(scenario_completed.model.t)

# The values model, to see if specific values of the noise level variable are significant
scenario_completed.model.v = brm(
  scenario_completed ~ 0 + Intercept + (suggestion_type + noise_level_f) + (gender + age_group + robot_experience) + num_optimal,
  family = "bernoulli",
  prior = set_prior("normal(0, 10)", class = "b"),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
scenario_completed.model.v = add_criterion(scenario_completed.model.v, "waic")
scenario_completed.model.v = add_criterion(scenario_completed.model.v, "loo", reloo = T)
saveModel(scenario_completed.model.v)
```
```{r, eval=!train_models}
# Load the models
scenario_completed.model.null = loadModel("scenario_completed.model.null")
scenario_completed.model.t = loadModel("scenario_completed.model.t")
scenario_completed.model.v = loadModel("scenario_completed.model.v")
```

Model fitting results:

```{r}
print(performance::r2(scenario_completed.model.null))

# Print the parameters, and some initial diagnostics
print(model_parameters(scenario_completed.model.t,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(scenario_completed.model.t))

print(model_parameters(scenario_completed.model.v,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(scenario_completed.model.v))
```

## Diagnostic

```{r fig.height=7, fig.width=15, eval=plot_diagnostics}
# Alternative diagnostics: diagnostic_posterior(scenario_completed.model.v)

# LOO cross-validation results
print(scenario_completed.model.null$criteria$loo$estimates)
print(scenario_completed.model.t$criteria$loo$estimates)
print(scenario_completed.model.v$criteria$loo$estimates)
print(loo_compare(scenario_completed.model.null,
                  scenario_completed.model.t,
                  scenario_completed.model.v))

# Diagnostics of the sampling process
par(mfrow=c(1,2))
plot(scenario_completed.model.t$criteria$loo, main = "Trend Model")
plot(scenario_completed.model.v$criteria$loo, main = "Values Model")

# Include posterior predictive checks of the sampling (are sampling according
# to the data that we actually have?)
# mcmc_intervals(as.matrix(scenario_completed.model.null), regex_pars = "b_", prob = 0.90, prob_outer = 0.95) +
#   ggtitle("Null Model")

p0 = pp_check(scenario_completed.model.null, type = "bars", stat = "median") + ggtitle("null model")

p1 = pp_check(scenario_completed.model.t, type = "bars_grouped", group = "suggestion_type", stat = "median") + ggtitle("t:suggestion_type")
p2 = pp_check(scenario_completed.model.t, type = "bars_grouped", group = "noise_level", stat = "median") + ggtitle("t:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(scenario_completed.model.t), regex_pars = "b_", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Trends Model")

p1 = pp_check(scenario_completed.model.v, type = "bars_grouped", group = "suggestion_type", stat = "median") + ggtitle("v:suggestion_type")
p2 = pp_check(scenario_completed.model.v, type = "bars_grouped", group = "noise_level_f", stat = "median") + ggtitle("v:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(scenario_completed.model.v), regex_pars = "b_", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Values Model")

# Plot predictions vs original
preds_p_df = scenario_completed.model.null %>% predict() %>% as_tibble()
p1 =
  preds_p_df %>%
    add_column(scenario_completed = scenario_completed.model.null$data$scenario_completed) %>%
    ggplot(aes(x = Estimate, y = scenario_completed, color = scenario_completed)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Null Model")

preds_p_df = plot_df %>%
  add_predicted_draws(scenario_completed.model.null) %>%
  group_by(scenario_completed, .prediction) %>%
  count()
p2 =
  preds_p_df %>%
    ggplot(aes(x = scenario_completed, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

preds_p_df = scenario_completed.model.t %>% predict() %>% as_tibble()
p3 =
  preds_p_df %>%
    add_column(scenario_completed = scenario_completed.model.t$data$scenario_completed) %>%
    ggplot(aes(x = Estimate, y = scenario_completed, color = scenario_completed)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Trends Model")

preds_p_df = plot_df %>%
  add_predicted_draws(scenario_completed.model.t) %>%
  group_by(scenario_completed, .prediction) %>%
  count()
p4 =
  preds_p_df %>%
    ggplot(aes(x = scenario_completed, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

# Plot predictions vs original
preds_p_df = scenario_completed.model.v %>% predict() %>% as_tibble()
p5 =
  preds_p_df %>%
    add_column(scenario_completed = scenario_completed.model.v$data$scenario_completed) %>%
    ggplot(aes(x = Estimate, y = scenario_completed, color = scenario_completed)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Values Model")

preds_p_df = plot_df %>%
  add_predicted_draws(scenario_completed.model.v) %>%
  group_by(scenario_completed, .prediction) %>%
  count()
p6 =
  preds_p_df %>%
    ggplot(aes(x = scenario_completed, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

grid.arrange(p1, p3, p5, p2, p4, p6, nrow = 2, ncol = 3)
rm(p0, p1, p2, p3, p4, p5, p6)
```

We are able to recreate the data, and there is a mild improvement in the recreation / prediction as a result of our model.

## Inference

```{r, eval=report_bayesfactors}
# Compute the bayes factor for each parameter value. Note: we compare
# here against the ROPE, and not the degenerate null hypothesis of 0
# Bayes-Factor values would be more significant in the latter case
# According to the Raftery, 1995 rules
# bf = 1 - 3: Weak
# bf = 3 - 20: Positive
# bf = 20 - 150: Strong
# bf > 150: Very strong
print(bayesfactor_rope(scenario_completed.model.null, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(scenario_completed.model.t, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(scenario_completed.model.v, null = c(-0.055, 0.055)), n = 30)
```
```{r}
options(digits = 3)
# Check the significance of each hypothesis
h_df = as_tibble(insight::get_parameters(scenario_completed.model.t)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = 2 * b_suggestion_type1,
    has_dx_test = (3 * b_suggestion_type2) + b_suggestion_type1,
    has_dxax_test = (4 * b_suggestion_type3) + b_suggestion_type1 + b_suggestion_type2,
    noise_levelL_test = b_noise_level.L,
    noise_levelQ_test = b_noise_level.Q
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())

h_df = as_tibble(insight::get_parameters(scenario_completed.model.v)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = 2 * b_suggestion_type1,
    has_dx_test = (3 * b_suggestion_type2) + b_suggestion_type1,
    has_dxax_test = (4 * b_suggestion_type3) + b_suggestion_type1 + b_suggestion_type2,
    noise_level1_test = b_noise_level_f1,
    noise_level2_test = b_noise_level_f2,
    noise_level3_test = - b_noise_level_f1 - b_noise_level_f2
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())
options(digits = 7)
```

**Results**:

1. AX suggestions
    - Positive effect pd = 97.2%
    - Median = 1.89, 89% CI [0.29, 3.37]
    - Large, Effect Size = 1.04
    - 0.73% in ROPE
1. DXAX suggestions
    - Positive effect pd = 96.2%
    - Median = 1.57, 89% CI [0.16, 2.97]
    - Large, Effect Size = 0.87
    - 1.15% in ROPE
1. Noise Level Quadratic
    - Positive (convex-shape) pd = 97.0%
    - Median = 0.77, 89% CI [0.12, 1.40]
    - Small, Effect Size = 0.42
    - 1.75% in ROPE

(The ROPE is defined as [-0.055, 0.055]. It is the range is suggested in the literature for logistic models and it corresponds to a probability range of 0.11. Therefore, a probability change of less than 0.055 is considered no different from a probability change of 0)

## Posterior Plots

```{r, eval=plot_posteriors}
# A visualization data frame
gg_df = plot_df %>%
  mutate(scenario_completed = factor(scenario_completed)) %>%
  mutate(scenario_completed = fct_recode(scenario_completed, incomplete="0", complete = "1")) %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  count(has_ax_only, has_dx_only, has_dxax, noise_level, scenario_completed)

# Simulate predictions on new data
p_df =
  plot_df %>%
  data_grid(scenario_completed,
            suggestion_type,
            noise_level_f,
            gender,
            age_group,
            robot_experience,
            num_optimal,
            .model = scenario_completed.model.v)

fits_p_df = p_df %>%
  add_fitted_draws(scenario_completed.model.v) %>%  # Linear predicted values
  mutate(has_ax_only = (suggestion_type == "AX"),
         has_dx_only = (suggestion_type == "DX"),
         has_dxax = (suggestion_type == "DXAX")) %>%
  mutate(has_ax_only = factor(has_ax_only, levels = c(F, T)),
         has_dx_only = factor(has_dx_only, levels = c(F, T)),
         has_dxax = factor(has_dxax, levels = c(F, T)))
pars_p_df = scenario_completed.model.t %>% extract_draws(newdata = p_df %>% rename(noise_level = noise_level_f))

# Plot the posterior distributions. In each of the following, the reference ROPE band
# can be marked based on 3 methods. Make sure to update that ROPE value baased on the
# method that we want to display.

# If centering ROPE on the Intercept (NULL or Fitted?)
# rope_value = inv_logit_scaled(fixef(scenario_completed.model.null)["Intercept","Estimate"])
# rope_value = inv_logit_scaled(fixef(scenario_completed.model.t)["Intercept","Estimate"])

# If centering ROPE on the actual data
# rope_value = gg_df %>%
#   filter(scenario_completed == 'complete', has_ax_only == F) %>%
#   summarise(.value = median(n) / 20) %>%
#   pull(.value)

# If centering ROPE on the posterior distributions. Here we center the ROPE around the posterior
# predicted value for the BASELINE condition
preds_p_df = p_df %>%
  add_predicted_draws(scenario_completed.model.v)  %>% # 0, 1 predictions for each predicted value
  ungroup() %>%
  count(suggestion_type, noise_level_f, .prediction) %>%
  mutate(has_ax_only = (suggestion_type == "AX"),
         has_dx_only = (suggestion_type == "DX"),
         has_dxax = (suggestion_type == "DXAX")) %>%
  mutate(has_ax_only = factor(has_ax_only, levels = c(F, T)),
         has_dx_only = factor(has_dx_only, levels = c(F, T)),
         has_dxax = factor(has_dxax, levels = c(F, T)))
rope_value = median(
  preds_p_df %>%
    filter(suggestion_type == "NONE") %>%
    spread(.prediction, n) %>%
    mutate(.value = `1` / (`0` + `1`)) %>%
    pull(.value)
)

gg_df %>%
  filter(scenario_completed == 'complete') %>%
  ggplot(aes(x = has_ax_only, y = n / 20)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "FRR", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(scenario_completed == 'complete') %>%
  ggplot(aes(x = has_dx_only, y = n / 20)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "FRR", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(scenario_completed == 'complete') %>%
  ggplot(aes(x = has_dxax, y = n / 20)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "FRR", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(scenario_completed == 'complete') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = n / 20)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "FRR", color = "AX:DX:DXAX:Noise")

# Create a plot to show the trend
pars_p_df_X = pars_p_df$dpars$mu$fe$X[,c("Intercept", "noise_level.Q")]
pars_p_df_b = pars_p_df$dpars$mu$fe$b[,c("b_Intercept", "b_noise_level.Q")]
pars_p_df_y = pars_p_df_X %*% t(pars_p_df_b)[,as.integer(seq(from = 1, to = 4000, length.out = 100))]
pars_p_df_y = inv_logit_scaled(pars_p_df_y)
p_df = p_df %>%
  bind_cols(as_tibble(pars_p_df_y)) %>%
  gather(key = ".sample", value = ".value", V1:V100) %>%
  rename(noise_level = noise_level_f)
gg_df %>%
  filter(scenario_completed == 'complete') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = n / 20)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_line(aes(y = .value, group = .sample, alpha = 0.3), data = p_df) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "FRR", color = "AX:DX:DXAX:Noise") +
    guides(alpha = F)

# Remove the giant fits data frames
rm(preds_p_df) # If using the posterior-predictions-based ROPE
rm(fits_p_df, pars_p_df, pars_p_df_b, pars_p_df_X, pars_p_df_y, p_df, gg_df)
```

```{r, eval=plot_paper_posteriors}
eff = fixef(scenario_completed.model.t)
base_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  - eff["suggestion_type1", "Estimate"]
  - eff["suggestion_type2", "Estimate"]
  - eff["suggestion_type3", "Estimate"]
)
ax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + eff["suggestion_type1", "Estimate"]
  - eff["suggestion_type2", "Estimate"]
  - eff["suggestion_type3", "Estimate"]
)
dx_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + (2 * eff["suggestion_type2", "Estimate"])
  - eff["suggestion_type3", "Estimate"]
)
dxax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + (3 * eff["suggestion_type3", "Estimate"])
)

gg_df = plot_df %>%
  mutate(scenario_completed = factor(scenario_completed)) %>%
  mutate(scenario_completed = fct_recode(scenario_completed, Unresolved="0", Resolved = "1")) %>%
  count(suggestion_type, has_ax_only, has_dx_only, has_dxax, noise_level, scenario_completed) %>%
  mutate(has_ax_only = fct_recode(has_ax_only, "No AX"="FALSE", "AX"="TRUE"),
         has_dx_only = fct_recode(has_dx_only, "No DX"="FALSE", "DX"="TRUE"),
         has_dxax = fct_recode(has_dxax, "No DXAX"="FALSE", "DXAX"="TRUE"),
         noise_level = fct_recode(noise_level, "Acc: 100%"="0.0", "Acc: 90%"="1.0", "Acc: 80%"="2.0")) %>%
  mutate(estimate = ifelse(suggestion_type == "NONE", base_eff, -1)) %>%
  mutate(estimate = ifelse(suggestion_type == "AX", ax_eff, estimate)) %>%
  mutate(estimate = ifelse(suggestion_type == "DX", dx_eff, estimate)) %>%
  mutate(estimate = ifelse(suggestion_type == "DXAX", dxax_eff, estimate))

p1 = gg_df %>%
  filter(scenario_completed == 'Resolved') %>%
  ggplot(aes(suggestion_type, n/20, group = suggestion_type, colour = suggestion_type)) +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    geom_signif(y_position = 1.05, xmin = 1, xmax = 2, annotation = "***", textsize = 8, color = "black") +
    geom_signif(y_position = 1.15, xmin = 1, xmax = 4, annotation = "***", textsize = 8, color = "black") +
    scale_y_continuous(limits = c(0.5, 1.2), breaks = c(0.5, 0.75, 1.0)) +
    labs(y = "Fraction of participants that resolved fault", x = NULL) +
    scale_colour_manual(values = c("#e51400", "#008a00", "#f0a30a", "#a4c400")) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank()) +
    legend_none()

eff = fixef(scenario_completed.model.v)
noise_0_eff = inv_logit_scaled(eff["Intercept", "Estimate"] + eff["noise_level_f1","Estimate"])
noise_1_eff = inv_logit_scaled(eff["Intercept", "Estimate"] + eff["noise_level_f2","Estimate"])
noise_2_eff = inv_logit_scaled(eff["Intercept", "Estimate"] - eff["noise_level_f1","Estimate"] - eff["noise_level_f2","Estimate"])

gg_df = gg_df %>%
  mutate(estimate = if_else(noise_level == "Acc: 100%", noise_0_eff, estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 90%", noise_1_eff, estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 80%", noise_2_eff, estimate)) %>%
  mutate(noise_level = fct_rev(noise_level))

p2 = gg_df %>%
  filter(scenario_completed == 'Resolved') %>%
  ggplot(aes(noise_level, n/20, group = noise_level, colour = noise_level)) +
    geom_hline(yintercept = inv_logit_scaled(eff["Intercept", "Estimate"]),
               size = .7, linetype = "dashed", color = "grey") +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    annotate("segment",
             x = 3, y = noise_0_eff,
             xend = 2, yend = noise_1_eff,
             colour = "black") +
    annotate("segment",
             x = 1, y = noise_2_eff,
             xend = 2, yend = noise_1_eff,
             color = "black") +
    annotate("text",
             x = 3.5,
             y = inv_logit_scaled(eff["Intercept", "Estimate"] - 0.85),
             label = "Mean of all levels",
             angle = 90,
             group = NA,
             colour = "black") +
    scale_y_continuous(limits = c(0.5, 1.1), breaks = c(0.5, 1.0)) +
    labs(y = "Fraction of participants that resolved fault", x = NULL) +
    scale_colour_manual(values = c("#e51400", "#008a00", "#f0a30a", "#a4c400")) +
    scale_size_area(max_size = 1) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
    legend_none()

grid.arrange(p1, p2, nrow = 1, ncol = 2)
rm(p1, p2)
```

```{r, echo=F, results=F, message=F, warning=F}
rm(scenario_completed.model.null, scenario_completed.model.t, scenario_completed.model.v)
gc()
```


# RAX: Rate of Optimal Action Selection

**Did the user take an optimal action given the state that they were in?**

This is also a measure of Reliance on Suggestions. In the code, the variable might be referred to as `optimal_ax`, `correct_ax`, etc. depending on the version of the codebase

```{r}
plot_df = actions %>%
  select(X1, id, user_id, study_condition, start_condition, num_optimal,
         state_idx, state_idx_rescaled,
         age_group, gender, robot_experience,
         noise_level, noise_level_f, has_noise, suggestion_type,
         has_dx, has_ax, has_ax_only, has_dx_only, has_dxax,
         scenario_completed, num_actions, optimal_ax)

print(summary(plot_df %>%
                mutate(optimal_ax = factor(optimal_ax),
                       scenario_completed = factor(scenario_completed)) %>%
                select(-X1, -id)
))
```

## Data

```{r fig.height=7, fig.width=15}
# Plot by the study condition
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(optimal_ax = factor(optimal_ax)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(optimal_ax = fct_recode(optimal_ax, incorrect="0", correct = "1")) %>%
    mutate(.fill_column = suggestion_type) %>%
    count(user_id, study_condition, .fill_column, optimal_ax, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
          name = "num_optimal_ax")

gg_df %>%
  ggplot(aes(user_id, num_optimal_ax / num_actions, fill=optimal_ax)) +
    geom_bar(stat="identity") +
    geom_hline(yintercept = 0.5) +
    facet_wrap(vars(study_condition), nrow = 1, scales = "free_y") +
    labs(y = "Fraction correct actions") +
    coord_flip() +
    scale_fill_economist()

gg_df %>%
  filter(optimal_ax == "correct") %>%
  ggplot(aes(study_condition, num_optimal_ax / num_actions, fill=.fill_column)) +
    geom_violin() +
    geom_boxplot(width = 0.1) +
    labs(y = "Fraction correct actions", fill = "Suggestion Type") +
    scale_fill_economist()

# Plot by suggestion type
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(optimal_ax = factor(optimal_ax)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(optimal_ax = fct_recode(optimal_ax, incorrect="0", correct = "1")) %>%
    count(user_id, suggestion_type, noise_level, optimal_ax, num_actions,
          name = "num_optimal_ax")

gg_df %>%
  filter(optimal_ax == "correct") %>%
  ggplot(aes(suggestion_type, num_optimal_ax / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(noise_level), labeller = label_both) +
    labs(y = "Fraction correct actions") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

gg_df %>%
  filter(optimal_ax == "correct") %>%
  ggplot(aes(noise_level, num_optimal_ax / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(suggestion_type)) +
    labs(y = "Fraction correct actions") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

p1 = gg_df %>%
  filter(optimal_ax == "correct") %>%
  ggplot(aes(suggestion_type, num_optimal_ax / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .2, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    legend_none()

p2 = gg_df %>%
  filter(optimal_ax == "correct") %>%
  ggplot(aes(noise_level, num_optimal_ax / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(color = "Type:Noise") +
    theme(legend.position = "right") +
    guides(size = F)

grid.arrange(p1, p2, ncol = 2)
```

## Model

Based on the data, we assume the following structural model:

$$RAX_{ij} = Bernoulli(p_{ij})$$
$$\begin{aligned}
logit(p_{ij}) &= \beta_0 + \beta_{0i} + \beta_{ax}\text{ax_only}_i + \beta_{dx}\text{dx_only}_i + \beta_{dxax}\text{dxax}_i +\\
&\beta_{noise_L}\text{noise}_i + \beta_{noise_Q}\text{noise}_i +\\
&\beta_{no}\text{no}_i + \mathbf{\beta_{demo}X_{demo,i}} + \beta_{state} \text{state}_{ij}
\end{aligned}$$
$$\begin{aligned}
\beta_{.} &\sim Normal(0, 10) \\
\beta_{0i} &\sim Normal(0, \sigma_i) \\
\sigma_i &\sim HalfStudent(3, 0, 10)
\end{aligned}$$

The prior for the $\sigma_i$ parameter is the default used in `brms`; I see no need to change it.

Model fitting:

```{r, eval=train_models}
# The null model
optimal_ax.model.null = brm(
  optimal_ax ~ 0 + Intercept + (1 | user_id),
  family = "bernoulli",
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
optimal_ax.model.null = add_criterion(optimal_ax.model.null, "waic")
optimal_ax.model.null = add_criterion(optimal_ax.model.null, "loo", reloo = T)
saveModel(optimal_ax.model.null)

# The trend model to see if there is a trend in the noise level variable
optimal_ax.model.t = brm(
  optimal_ax ~ 0 + Intercept + (suggestion_type + noise_level) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
optimal_ax.model.t = add_criterion(optimal_ax.model.t, "waic")
optimal_ax.model.t = add_criterion(optimal_ax.model.t, "loo", reloo = T)
saveModel(optimal_ax.model.t)

# The values model, to see if specific values of the noise level variable are significant
optimal_ax.model.v = brm(
  optimal_ax ~ 0 + Intercept + (suggestion_type + noise_level_f) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
optimal_ax.model.v = add_criterion(optimal_ax.model.v, "waic")
optimal_ax.model.v = add_criterion(optimal_ax.model.v, "loo", reloo = T)
saveModel(optimal_ax.model.v)
```
```{r, eval=!train_models}
# Load the models
optimal_ax.model.null = loadModel("optimal_ax.model.null")
optimal_ax.model.t = loadModel("optimal_ax.model.t")
optimal_ax.model.v = loadModel("optimal_ax.model.v")
```

Model fitting results:

```{r}
print(performance::r2(optimal_ax.model.null))

# Print the parameters, and some initial diagnostics
print(model_parameters(optimal_ax.model.t,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(optimal_ax.model.t))

print(model_parameters(optimal_ax.model.v,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(optimal_ax.model.v))
```

## Diagnostic

```{r fig.height=7, fig.width=15, eval=plot_diagnostics}
# Alternative diagnostics: diagnostic_posterior(scenario_completed.model.v)

# LOO cross-validation results
print(optimal_ax.model.t$criteria$loo$estimates)
print(optimal_ax.model.v$criteria$loo$estimates)
print(loo_compare(optimal_ax.model.null, optimal_ax.model.t, optimal_ax.model.v))

# Diagnostics of the sampling process
par(mfrow=c(1,2))
plot(optimal_ax.model.t$criteria$loo, main = "Trend Model")
plot(optimal_ax.model.v$criteria$loo, main = "Values Model")

# Include posterior predictive checks of the sampling (are sampling according
# to the data that we actually have?)
p0 = pp_check(optimal_ax.model.null, type = "bars", stat = "median") + ggtitle("null model")

p1 = pp_check(optimal_ax.model.t, type = "bars_grouped", group = "suggestion_type", stat = "median") + ggtitle("t:suggestion_type")
p2 = pp_check(optimal_ax.model.t, type = "bars_grouped", group = "noise_level", stat = "median") + ggtitle("t:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(optimal_ax.model.t), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Trends Model")

p1 = pp_check(optimal_ax.model.v, type = "bars_grouped", group = "suggestion_type", stat = "median") + ggtitle("v:suggestion_type")
p4 = pp_check(optimal_ax.model.v, type = "bars_grouped", group = "noise_level_f", stat = "median") + ggtitle("v:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(optimal_ax.model.v), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Values Model")

# Plot predictions vs original
preds_p_df = optimal_ax.model.null %>% predict() %>% as_tibble()
p1 =
  preds_p_df %>%
    add_column(optimal_ax = optimal_ax.model.null$data$optimal_ax) %>%
    ggplot(aes(x = Estimate, y = optimal_ax, color = optimal_ax)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Null Model")

preds_p_df = plot_df %>%
  add_predicted_draws(optimal_ax.model.null) %>%
  group_by(optimal_ax, .prediction) %>%
  count()
p2 =
  preds_p_df %>%
    ggplot(aes(x = optimal_ax, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

preds_p_df = optimal_ax.model.t %>% predict() %>% as_tibble()
p3 =
  preds_p_df %>%
    add_column(optimal_ax = optimal_ax.model.t$data$optimal_ax) %>%
    ggplot(aes(x = Estimate, y = optimal_ax, color = optimal_ax)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Trends Model")

preds_p_df = plot_df %>%
  add_predicted_draws(optimal_ax.model.t) %>%
  group_by(optimal_ax, .prediction) %>%
  count()
p4 =
  preds_p_df %>%
    ggplot(aes(x = optimal_ax, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

# Plot predictions vs original
preds_p_df = optimal_ax.model.v %>% predict() %>% as_tibble()
p5 =
  preds_p_df %>%
    add_column(optimal_ax = optimal_ax.model.v$data$optimal_ax) %>%
    ggplot(aes(x = Estimate, y = optimal_ax, color = optimal_ax)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Values Model")

preds_p_df = plot_df %>%
  add_predicted_draws(optimal_ax.model.v) %>%
  group_by(optimal_ax, .prediction) %>%
  count()
p6 =
  preds_p_df %>%
    ggplot(aes(x = optimal_ax, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

grid.arrange(p1, p3, p5, p2, p4, p6, nrow = 2, ncol = 3)
rm(p0, p1, p2, p3, p4, p5, p6)
```

We are better able to recreate the data, if only marginally, with the model.

## Inference

```{r, eval=report_bayesfactors}
# Compute the bayes factor for each parameter value. Note: we compare
# here against the ROPE, and not the degenerate null hypothesis of 0
# Bayes-Factor values would be more significant in the latter case
# According to the Raftery, 1995 rules
# bf = 1 - 3: Weak
# bf = 3 - 20: Positive
# bf = 20 - 150: Strong
# bf > 150: Very strong
print(bayesfactor_rope(optimal_ax.model.null, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(optimal_ax.model.t, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(optimal_ax.model.v, null = c(-0.055, 0.055)), n = 30)
```
```{r}
options(digits = 3)
# Check the significance of each hypothesis
h_df = as_tibble(insight::get_parameters(optimal_ax.model.t)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = 2 * b_suggestion_type1,
    has_dx_test = (3 * b_suggestion_type2) + b_suggestion_type1,
    has_dxax_test = (4 * b_suggestion_type3) + b_suggestion_type1 + b_suggestion_type2,
    noise_levelL_test = b_noise_level.L,
    noise_levelQ_test = b_noise_level.Q
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())

h_df = as_tibble(insight::get_parameters(optimal_ax.model.v)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = 2 * b_suggestion_type1,
    has_dx_test = (3 * b_suggestion_type2) + b_suggestion_type1,
    has_dxax_test = (4 * b_suggestion_type3) + b_suggestion_type1 + b_suggestion_type2,
    noise_level1_test = b_noise_level_f1,
    noise_level2_test = b_noise_level_f2,
    noise_level3_test = - b_noise_level_f1 - b_noise_level_f2
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())
options(digits = 7)
```

**Results**:

1. AX suggestions
    - Positive effect pd = 97.0%
    - Median = 1.03, 89% CI [0.16, 1.95]
    - Medium, Effect Size = 0.57
    - 1.98% in ROPE
1. DXAX suggestions
    - Positive effect pd = 99.0%
    - Median = 1.20, 89% CI [0.39, 2.09]
    - Medium, Effect Size = 0.66
    - 0.50% in ROPE

(The ROPE is defined as [-0.055, 0.055]. It is the range is suggested in the literature for logistic models and it corresponds to a probability range of 0.11. Therefore, a probability change of less than 0.055 is considered no different from a probability change of 0)

## Posterior Plots

```{r eval=plot_posteriors}
# A visualization data frame
gg_df = plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(optimal_ax = factor(optimal_ax)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(optimal_ax = fct_recode(optimal_ax, incorrect="0", correct = "1")) %>%
    count(user_id, optimal_ax, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
          name = "num_optimal_ax")

# Simulate predictions on new data
p_df =
  plot_df %>%
  data_grid(optimal_ax,
            suggestion_type,
            noise_level_f,
            gender,
            age_group,
            robot_experience,
            num_optimal,
            state_idx_rescaled = seq_range(state_idx_rescaled, n = 4),
            .model = optimal_ax.model.v)

fits_p_df = p_df %>%
  add_fitted_draws(optimal_ax.model.v, re_formula = NA, n = 20, seed = default_seed) %>%
  mutate(has_ax_only = (suggestion_type == "AX"),
         has_dx_only = (suggestion_type == "DX"),
         has_dxax = (suggestion_type == "DXAX")) %>%
  mutate(has_ax_only = factor(has_ax_only, levels = c(F, T)),
         has_dx_only = factor(has_dx_only, levels = c(F, T)),
         has_dxax = factor(has_dxax, levels = c(F, T)))

gc()

# Plot the posterior distributions. In each of the following, the reference ROPE band
# can be marked based on 3 methods. Make sure to update that ROPE value baased on the
# method that we want to display.

# If centering the ROPE on the Intercept (NULL or Fitted?)
# rope_value = inv_logit_scaled(fixef(optimal_ax.model.null)["Intercept", "Estimate"])
# rope_value = inv_logit_scaled(fixef(optimal_ax.model.t)["Intercept", "Estimate"])

# If centering the ROPE on the actual data
# rope_value = gg_df %>%
#   filter(optimal_ax == 'correct', has_ax == F) %>%
#   summarise(.value = median(num_optimal_ax / num_actions)) %>%
#   pull(.value)

# If centering ROPE on the posterior distributions. Here we center the ROPE around the posterior
# predicted value for the BASELINE condition
preds_p_df = p_df %>%
  add_predicted_draws(optimal_ax.model.v, re_formula = NA)  %>% # 0, 1 predictions for each predicted value
  ungroup() %>%
  count(suggestion_type, noise_level_f, .prediction) %>%
  mutate(has_ax_only = (suggestion_type == "AX"),
         has_dx_only = (suggestion_type == "DX"),
         has_dxax = (suggestion_type == "DXAX")) %>%
  mutate(has_ax_only = factor(has_ax_only, levels = c(F, T)),
         has_dx_only = factor(has_dx_only, levels = c(F, T)),
         has_dxax = factor(has_dxax, levels = c(F, T)))
rope_value = median(
  preds_p_df %>%
    filter(suggestion_type == "NONE") %>%
    spread(.prediction, n) %>%
    mutate(.value = `1` / (`0` + `1`)) %>%
    pull(.value)
)
gc()

gg_df %>%
  filter(optimal_ax == 'correct') %>%
  ggplot(aes(x = has_ax_only, y = num_optimal_ax / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RAX", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(optimal_ax == 'correct') %>%
  ggplot(aes(x = has_dx_only, y = num_optimal_ax / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RAX", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(optimal_ax == 'correct') %>%
  ggplot(aes(x = has_dxax, y = num_optimal_ax / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RAX", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(optimal_ax == 'correct') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = num_optimal_ax / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RAX", color = "AX:DX:DXAX:Noise")

# Remove the giant fits data frames
rm(preds_p_df) # If using the posterior-predictions-based ROPE
rm(fits_p_df, p_df, gg_df)
```

```{r, eval=plot_paper_posteriors}
eff = fixef(optimal_ax.model.t)
base_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  - eff["suggestion_type1", "Estimate"]
  - eff["suggestion_type2", "Estimate"]
  - eff["suggestion_type3", "Estimate"]
)
ax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + eff["suggestion_type1", "Estimate"]
  - eff["suggestion_type2", "Estimate"]
  - eff["suggestion_type3", "Estimate"]
)
dx_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + (2 * eff["suggestion_type2", "Estimate"])
  - eff["suggestion_type3", "Estimate"]
)
dxax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + (3 * eff["suggestion_type3", "Estimate"])
)

gg_df = plot_df %>%
  mutate(scenario_completed = factor(scenario_completed)) %>%
  mutate(scenario_completed = fct_recode(scenario_completed, Unresolved="0", Resolved = "1"),
         has_ax_only = fct_recode(has_ax_only, "No AX"="FALSE", "AX"="TRUE"),
         has_dx_only = fct_recode(has_dx_only, "No DX"="FALSE", "DX"="TRUE"),
         has_dxax = fct_recode(has_dxax, "No DXAX"="FALSE", "DXAX"="TRUE"),
         noise_level = fct_recode(noise_level, "Acc: 100%"="0.0", "Acc: 90%"="1.0", "Acc: 80%"="2.0")) %>%
  count(user_id, suggestion_type, optimal_ax, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
        name = "num_optimal_ax") %>%
  mutate(estimate = ifelse(suggestion_type == "NONE", base_eff, -1)) %>%
  mutate(estimate = ifelse(suggestion_type == "AX", ax_eff, estimate)) %>%
  mutate(estimate = ifelse(suggestion_type == "DX", dx_eff, estimate)) %>%
  mutate(estimate = ifelse(suggestion_type == "DXAX", dxax_eff, estimate))

gg_df %>%
  filter(optimal_ax == "1") %>%
  ggplot(aes(suggestion_type, num_optimal_ax / num_actions, group = suggestion_type, colour=suggestion_type)) +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    geom_signif(y_position = 1.05, xmin = 1, xmax = 2, annotation = "**", textsize = 8, color = "black") +
    geom_signif(y_position = 1.15, xmin = 1, xmax = 4, annotation = "**", textsize = 8, color = "black") +
    scale_y_continuous(limits = c(0.0, 1.2), breaks = c(0.0, 0.5, 1.0)) +
    labs(y = NULL, x = NULL) +
    scale_colour_manual(values = c("#e51400", "#008a00", "#f0a30a", "#a4c400")) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank()) +
    legend_none()
```

```{r, echo=F, results=F, message=F, warning=F}
rm(optimal_ax.model.null, optimal_ax.model.t, optimal_ax.model.v)
gc()
```


# RDX: Rate of Correct Diagnosis Selection

**Did the user figure out the correct diagnoses for their situation?**

This is also a measure of Reliance on Suggestions. In the code, the variable might be referred to as `optimal_dx`, `correct_dx`, etc. depending on the version of the codebase

```{r}
plot_df = actions %>%
  select(X1, id, user_id, study_condition, start_condition, num_optimal,
         state_idx, state_idx_rescaled,
         age_group, gender, robot_experience,
         noise_level, noise_level_f, has_noise, suggestion_type,
         has_dx, has_ax, has_ax_only, has_dx_only, has_dxax,
         scenario_completed, num_actions, optimal_dx)

print(summary(plot_df %>%
                mutate(optimal_ax = factor(optimal_dx),
                       scenario_completed = factor(scenario_completed)) %>%
                select(-X1, -id)
))
```

## Data

```{r fig.height=7, fig.width=15}
# Plot by the study condition
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(optimal_dx = factor(optimal_dx)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(optimal_dx = fct_recode(optimal_dx, incorrect="0", correct = "1")) %>%
    mutate(.fill_column = suggestion_type) %>%
    count(user_id, study_condition, .fill_column, optimal_dx, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
          name = "num_optimal_dx")

gg_df %>%
  ggplot(aes(user_id, num_optimal_dx / num_actions, fill=optimal_dx)) +
    geom_bar(stat="identity") +
    geom_hline(yintercept = 0.5) +
    facet_wrap(vars(study_condition), nrow = 1, scales = "free_y") +
    labs(y = "Fraction correct diagnoses") +
    coord_flip() +
    scale_fill_economist()

gg_df %>%
  filter(optimal_dx == "correct") %>%
  ggplot(aes(study_condition, num_optimal_dx / num_actions, fill=.fill_column)) +
    geom_violin() +
    geom_boxplot(width = 0.1) +
    labs(y = "Fraction correct diagnoses", fill = "Suggestion Type") +
    scale_fill_economist()

# Plot by suggestion type
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(optimal_dx = factor(optimal_dx)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(optimal_dx = fct_recode(optimal_dx, incorrect="0", correct = "1")) %>%
    count(user_id, suggestion_type, noise_level, optimal_dx, num_actions,
          name = "num_optimal_dx")

gg_df %>%
  filter(optimal_dx == "correct") %>%
  ggplot(aes(suggestion_type, num_optimal_dx / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(noise_level), labeller = label_both) +
    labs(y = "Fraction correct diagnoses") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

gg_df %>%
  filter(optimal_dx == "correct") %>%
  ggplot(aes(noise_level, num_optimal_dx / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(suggestion_type)) +
    labs(y = "Fraction correct diagnoses") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

p1 = gg_df %>%
  filter(optimal_dx == "correct") %>%
  ggplot(aes(suggestion_type, num_optimal_dx / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .2, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    legend_none()

p2 = gg_df %>%
  filter(optimal_dx == "correct") %>%
  ggplot(aes(noise_level, num_optimal_dx / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(color = "Type:Noise") +
    theme(legend.position = "right") +
    guides(size = F)

grid.arrange(p1, p2, ncol = 2)
```

## Model

Based on the data, we assume the following structural model:

$$RDX_{ij} = Bernoulli(p_{ij})$$
$$\begin{aligned}
logit(p_{ij}) &= \beta_0 + \beta_{0i} + \beta_{ax}\text{ax_only}_i + \beta_{dx}\text{dx_only}_i + \beta_{dxax}\text{dxax}_i +\\
&\beta_{noise_L}\text{noise}_i + \beta_{noise_Q}\text{noise}_i +\\
&\beta_{no}\text{no}_i + \mathbf{\beta_{demo}X_{demo,i}} + \beta_{state} \text{state}_{ij}
\end{aligned}$$
$$\begin{aligned}
\beta_{.} &\sim Normal(0, 10) \\
\beta_{0i} &\sim Normal(0, \sigma_i) \\
\sigma_i &\sim HalfStudent(3, 0, 10)
\end{aligned}$$

The prior for the $\sigma_i$ parameter is the default used in `brms`; I see no need to change it.

Model fitting:

```{r, eval=train_models}
# The null model
optimal_dx.model.null = brm(
  optimal_dx ~ 0 + Intercept + (1 | user_id),
  family = "bernoulli",
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
optimal_dx.model.null = add_criterion(optimal_dx.model.null, "waic")
optimal_dx.model.null = add_criterion(optimal_dx.model.null, "loo", reloo = T)
saveModel(optimal_dx.model.null)

# The trend model to see if there is a trend in the noise level variable
optimal_dx.model.t = brm(
  optimal_dx ~ 0 + Intercept + (suggestion_type + noise_level) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
optimal_dx.model.t = add_criterion(optimal_dx.model.t, "waic")
optimal_dx.model.t = add_criterion(optimal_dx.model.t, "loo", reloo = T)
saveModel(optimal_dx.model.t)

# The values model, to see if specific values of the noise level variable are significant
optimal_dx.model.v = brm(
  optimal_dx ~ 0 + Intercept + (suggestion_type + noise_level_f) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
optimal_dx.model.v = add_criterion(optimal_dx.model.v, "waic")
optimal_dx.model.v = add_criterion(optimal_dx.model.v, "loo", reloo = T)
saveModel(optimal_dx.model.v)
```
```{r, eval=!train_models}
# Load the models
optimal_dx.model.null = loadModel("optimal_dx.model.null")
optimal_dx.model.t = loadModel("optimal_dx.model.t")
optimal_dx.model.v = loadModel("optimal_dx.model.v")
```

Model fitting results:

```{r}
print(performance::r2(optimal_dx.model.null))

# Print the parameters, and some initial diagnostics
print(model_parameters(optimal_dx.model.t,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(optimal_dx.model.t))

print(model_parameters(optimal_dx.model.v,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(optimal_dx.model.v))
```

## Diagnostic

```{r fig.height=7, fig.width=15, eval=plot_diagnostics}
# Alternative diagnostics: diagnostic_posterior(scenario_completed.model.v)

# LOO cross-validation results
print(optimal_dx.model.t$criteria$loo$estimates)
print(optimal_dx.model.v$criteria$loo$estimates)
print(loo_compare(optimal_dx.model.null, optimal_dx.model.t, optimal_dx.model.v))

# Diagnostics of the sampling process
par(mfrow=c(1,2))
plot(optimal_dx.model.t$criteria$loo, main = "Trend Model")
plot(optimal_dx.model.v$criteria$loo, main = "Values Model")

# Include posterior predictive checks of the sampling (are sampling according
# to the data that we actually have?)
p0 = pp_check(optimal_dx.model.null, type = "bars", stat = "median") + ggtitle("null model")

p1 = pp_check(optimal_dx.model.t, type = "bars_grouped", group = "suggestion_type", stat = "median") + ggtitle("t:suggestion_type")
p2 = pp_check(optimal_dx.model.t, type = "bars_grouped", group = "noise_level", stat = "median") + ggtitle("t:noise_level")
grid.arrange(p1, p2, p0, ncol = 2, nrow = 2)
mcmc_intervals(as.matrix(optimal_dx.model.t), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Trends Model")

p1 = pp_check(optimal_dx.model.v, type = "bars_grouped", group = "suggestion_type", stat = "median") + ggtitle("v:suggestion_type")
p2 = pp_check(optimal_dx.model.v, type = "bars_grouped", group = "noise_level_f", stat = "median") + ggtitle("v:noise_level")
grid.arrange(p1, p2, p0, ncol = 2, nrow = 2)
mcmc_intervals(as.matrix(optimal_dx.model.v), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Values Model")

# Plot predictions vs original
preds_p_df = optimal_dx.model.null %>% predict() %>% as_tibble()
p1 =
  preds_p_df %>%
    add_column(optimal_dx = optimal_dx.model.null$data$optimal_dx) %>%
    ggplot(aes(x = Estimate, y = optimal_dx, color = optimal_dx)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Null Model")

preds_p_df = plot_df %>%
  add_predicted_draws(optimal_dx.model.null) %>%
  group_by(optimal_dx, .prediction) %>%
  count()
p2 =
  preds_p_df %>%
    ggplot(aes(x = optimal_dx, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

preds_p_df = optimal_dx.model.t %>% predict() %>% as_tibble()
p3 =
  preds_p_df %>%
    add_column(optimal_dx = optimal_dx.model.t$data$optimal_dx) %>%
    ggplot(aes(x = Estimate, y = optimal_dx, color = optimal_dx)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Trends Model")

preds_p_df = plot_df %>%
  add_predicted_draws(optimal_dx.model.t) %>%
  group_by(optimal_dx, .prediction) %>%
  count()
p4 =
  preds_p_df %>%
    ggplot(aes(x = optimal_dx, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

# Plot predictions vs original
preds_p_df = optimal_dx.model.v %>% predict() %>% as_tibble()
p5 =
  preds_p_df %>%
    add_column(optimal_dx = optimal_dx.model.v$data$optimal_dx) %>%
    ggplot(aes(x = Estimate, y = optimal_dx, color = optimal_dx)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Values Model")

preds_p_df = plot_df %>%
  add_predicted_draws(optimal_dx.model.v) %>%
  group_by(optimal_dx, .prediction) %>%
  count()
p6 =
  preds_p_df %>%
    ggplot(aes(x = optimal_dx, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

grid.arrange(p1, p3, p5, p2, p4, p6, nrow = 2, ncol = 3)
rm(p0, p1, p2, p3, p4, p5, p6)
```

We are better able to recreate the data, if only marginally, with the model.

## Inference

```{r, eval=report_bayesfactors}
# Compute the bayes factor for each parameter value. Note: we compare
# here against the ROPE, and not the degenerate null hypothesis of 0
# Bayes-Factor values would be more significant in the latter case
# According to the Raftery, 1995 rules
# bf = 1 - 3: Weak
# bf = 3 - 20: Positive
# bf = 20 - 150: Strong
# bf > 150: Very strong
print(bayesfactor_rope(optimal_dx.model.null, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(optimal_dx.model.t, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(optimal_dx.model.v, null = c(-0.055, 0.055)), n = 30)
```
```{r}
options(digits = 3)
# Check the significance of each hypothesis
h_df = as_tibble(insight::get_parameters(optimal_dx.model.t)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = 2 * b_suggestion_type1,
    has_dx_test = (3 * b_suggestion_type2) + b_suggestion_type1,
    has_dxax_test = (4 * b_suggestion_type3) + b_suggestion_type1 + b_suggestion_type2,
    noise_levelL_test = b_noise_level.L,
    noise_levelQ_test = b_noise_level.Q
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())

h_df = as_tibble(insight::get_parameters(optimal_dx.model.v)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = 2 * b_suggestion_type1,
    has_dx_test = (3 * b_suggestion_type2) + b_suggestion_type1,
    has_dxax_test = (4 * b_suggestion_type3) + b_suggestion_type1 + b_suggestion_type2,
    noise_level1_test = b_noise_level_f1,
    noise_level2_test = b_noise_level_f2,
    noise_level3_test = - b_noise_level_f1 - b_noise_level_f2
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())
options(digits = 7)
```

**Results**:

1. DX suggestions
    - Positive effect pd = 97.8%
    - Median = 0.82, 89% CI [0.15, 1.51]
    - Small, Effect Size = 0.45
    - 1.60% in ROPE
1. DXAX suggestions
    - Positive effect pd = 98.7%
    - Median = 0.92, 89% CI [0.22, 1.60]
    - Medium, Effect Size = 0.51
    - 0.98% in ROPE
1. Noise Level Linear
    - Negative (negative slope) pd = 99.3%
    - Median = -0.48, 89% CI [-0.79, -0.16]
    - Small, Effect Size = 0.26
    - 1.25% in ROPE

(The ROPE is defined as [-0.055, 0.055]. It is the range is suggested in the literature for logistic models and it corresponds to a probability range of 0.11. Therefore, a probability change of less than 0.055 is considered no different from a probability change of 0)

## Posterior Plots

```{r eval=plot_posteriors}
# A visualization data frame
gg_df = plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(optimal_dx = factor(optimal_dx)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(optimal_dx = fct_recode(optimal_dx, incorrect="0", correct = "1")) %>%
    count(user_id, optimal_dx, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
          name = "num_optimal_dx")

# Simulate predictions on new data
p_df =
  plot_df %>%
  data_grid(optimal_dx,
            suggestion_type,
            noise_level_f,
            gender,
            age_group,
            robot_experience,
            num_optimal,
            state_idx_rescaled = seq_range(state_idx_rescaled, n = 4),
            .model = optimal_dx.model.v)

fits_p_df = p_df %>%
  add_fitted_draws(optimal_dx.model.v, re_formula = NA, n = 20, seed = default_seed) %>%
  mutate(has_ax_only = (suggestion_type == "AX"),
         has_dx_only = (suggestion_type == "DX"),
         has_dxax = (suggestion_type == "DXAX")) %>%
  mutate(has_ax_only = factor(has_ax_only, levels = c(F, T)),
         has_dx_only = factor(has_dx_only, levels = c(F, T)),
         has_dxax = factor(has_dxax, levels = c(F, T)))
gc()

pars_p_df = optimal_dx.model.t %>%
  extract_draws(newdata = p_df %>% rename(noise_level = noise_level_f), re_formula = NA, nsamples = 100)
gc()

# Plot the posterior distributions. In each of the following, the reference ROPE band
# can be marked based on 3 methods. Make sure to update that ROPE value baased on the
# method that we want to display.

# If centering ROPE on the posterior distributions. Here we center the ROPE around the posterior
# predicted value for the BASELINE condition
preds_p_df = p_df %>%
  add_predicted_draws(optimal_dx.model.v, re_formula = NA)  %>% # 0, 1 predictions for each predicted value
  ungroup() %>%
  count(suggestion_type, noise_level_f, .prediction) %>%
  mutate(has_ax_only = (suggestion_type == "AX"),
         has_dx_only = (suggestion_type == "DX"),
         has_dxax = (suggestion_type == "DXAX")) %>%
  mutate(has_ax_only = factor(has_ax_only, levels = c(F, T)),
         has_dx_only = factor(has_dx_only, levels = c(F, T)),
         has_dxax = factor(has_dxax, levels = c(F, T)))
rope_value = median(
  preds_p_df %>%
    filter(suggestion_type == "NONE") %>%
    spread(.prediction, n) %>%
    mutate(.value = `1` / (`0` + `1`)) %>%
    pull(.value)
)
gc()

# Plot the posterior distributions
gg_df %>%
  filter(optimal_dx == 'correct') %>%
  ggplot(aes(x = has_ax_only, y = num_optimal_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RDX", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(optimal_dx == 'correct') %>%
  ggplot(aes(x = has_dx_only, y = num_optimal_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RDX", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(optimal_dx == 'correct') %>%
  ggplot(aes(x = has_dxax, y = num_optimal_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RDX", color = "AX:DX:DXAX:Noise")

gg_df %>%
  filter(optimal_dx == 'correct') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = num_optimal_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RDX", color = "AX:DX:DXAX:Noise")

# Create a plot to show the trend
pars_p_df_X = pars_p_df$dpars$mu$fe$X[,c("Intercept", "noise_level.L")]
pars_p_df_b = pars_p_df$dpars$mu$fe$b[,c("b_Intercept", "b_noise_level.L")]
pars_p_df_y = pars_p_df_X %*% t(pars_p_df_b)
pars_p_df_y = inv_logit_scaled(pars_p_df_y)
p_df =p_df %>%
  bind_cols(as_tibble(pars_p_df_y)) %>%
  gather(key = ".sample", value = ".value", V1:V100) %>%
  rename(noise_level = noise_level_f)
gg_df %>%
  filter(optimal_dx == 'correct') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = num_optimal_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_line(aes(y = .value, group = .sample, alpha = 0.3), data = p_df) +
    geom_point(aes(color = paste(has_ax_only, has_dx_only, has_dxax, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "RDX", color = "AX:DX:DXAX:Noise") +
    guides(alpha = F)

# Remove the giant fits data frames
rm(preds_p_df) # If using the posterior-predictions-based ROPE
rm(fits_p_df, pars_p_df, pars_p_df_b, pars_p_df_X, pars_p_df_y, p_df, gg_df)
```

```{r, eval=plot_paper_posteriors}
eff = fixef(optimal_dx.model.t)
base_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  - eff["suggestion_type1", "Estimate"]
  - eff["suggestion_type2", "Estimate"]
  - eff["suggestion_type3", "Estimate"]
)
ax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + eff["suggestion_type1", "Estimate"]
  - eff["suggestion_type2", "Estimate"]
  - eff["suggestion_type3", "Estimate"]
)
dx_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + (2 * eff["suggestion_type2", "Estimate"])
  - eff["suggestion_type3", "Estimate"]
)
dxax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + (3 * eff["suggestion_type3", "Estimate"])
)

gg_df = plot_df %>%
  mutate(scenario_completed = factor(scenario_completed)) %>%
  mutate(scenario_completed = fct_recode(scenario_completed, Unresolved="0", Resolved = "1"),
         has_ax_only = fct_recode(has_ax_only, "No AX"="FALSE", "AX"="TRUE"),
         has_dx_only = fct_recode(has_dx_only, "No DX"="FALSE", "DX"="TRUE"),
         has_dxax = fct_recode(has_dxax, "No DXAX"="FALSE", "DXAX"="TRUE"),
         noise_level = fct_recode(noise_level, "Acc: 100%"="0.0", "Acc: 90%"="1.0", "Acc: 80%"="2.0")) %>%
  count(user_id, suggestion_type, optimal_dx, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
        name = "num_optimal_dx") %>%
  mutate(estimate = ifelse(suggestion_type == "NONE", base_eff, -1)) %>%
  mutate(estimate = ifelse(suggestion_type == "AX", ax_eff, estimate)) %>%
  mutate(estimate = ifelse(suggestion_type == "DX", dx_eff, estimate)) %>%
  mutate(estimate = ifelse(suggestion_type == "DXAX", dxax_eff, estimate))

p1 = gg_df %>%
  filter(optimal_dx == "1") %>%
  ggplot(aes(suggestion_type, num_optimal_dx / num_actions, group = suggestion_type, colour=suggestion_type)) +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    geom_signif(y_position = 1.05, xmin = 1, xmax = 3, annotation = "*", textsize = 8, color = "black") +
    geom_signif(y_position = 1.15, xmin = 1, xmax = 4, annotation = "**", textsize = 8, color = "black") +
    scale_y_continuous(limits = c(0.0, 1.2), breaks = c(0.0, 0.5, 1.0)) +
    labs(y = NULL, x = NULL) +
    scale_colour_manual(values = c("#e51400", "#008a00", "#f0a30a", "#a4c400")) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank()) +
    legend_none()

eff = fixef(optimal_dx.model.v)
noise_0_eff = inv_logit_scaled(eff["Intercept", "Estimate"] + eff["noise_level_f1","Estimate"])
noise_1_eff = inv_logit_scaled(eff["Intercept", "Estimate"] + eff["noise_level_f2","Estimate"])
noise_2_eff = inv_logit_scaled(eff["Intercept", "Estimate"] - eff["noise_level_f1","Estimate"] - eff["noise_level_f2","Estimate"])

gg_df = gg_df %>%
  mutate(estimate = if_else(noise_level == "Acc: 100%", noise_0_eff, estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 90%", noise_1_eff, estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 80%", noise_2_eff, estimate)) %>%
  mutate(noise_level = fct_rev(noise_level))

p2 = gg_df %>%
  filter(optimal_dx == "1") %>%
  ggplot(aes(noise_level, num_optimal_dx / num_actions, group = noise_level, colour = noise_level)) +
    geom_hline(yintercept = inv_logit_scaled(eff["Intercept", "Estimate"]),
               size = .7, linetype = "dashed", color = "grey") +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    annotate("segment",
             x = 3, y = noise_0_eff,
             xend = 2, yend = noise_1_eff,
             colour = "black") +
    annotate("segment",
             x = 1, y = noise_2_eff,
             xend = 2, yend = noise_1_eff,
             color = "black") +
    annotate("text",
             x = 3.5,
             y = inv_logit_scaled(eff["Intercept", "Estimate"] - 0.35),
             label = "Mean of all levels",
             angle = 90,
             group = NA,
             colour = "black") +
    scale_y_continuous(limits = c(0.0, 1.0), breaks = c(0.0, 0.5, 1.0)) +
    labs(y = "RDX", x = NULL) +
    scale_colour_manual(values = c("#e51400", "#008a00", "#f0a30a", "#a4c400")) +
    scale_size_area(max_size = 1) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
    legend_none()

grid.arrange(p1, p2, nrow = 1, ncol = 2)
rm(p1, p2)
```

```{r, echo=F, results=F, message=F, warning=F}
rm(optimal_dx.model.null, optimal_dx.model.t, optimal_dx.model.v)
gc()
```


# CAX: Compliance with AX Suggestions

**Did the user follow the AX suggestions that were provided to them?**

In the code, the variable might be referred to as `chose_ax`, `follow_ax`, etc. depending on the version of the codebase

```{r}
plot_df = actions %>%
  filter(has_ax == T) %>%
  select(X1, id, user_id, study_condition, start_condition, num_optimal,
         state_idx, state_idx_rescaled,
         age_group, gender, robot_experience,
         noise_level, noise_level_f, has_noise, suggestion_type,
         has_dx, has_ax, has_ax_only, has_dx_only, has_dxax,
         scenario_completed, num_actions, chose_ax)

# With these dropped levels, the suggestion_type variable is the same as the
# boolean flags for each suggestion type
plot_df$suggestion_type = droplevels(plot_df$suggestion_type)

print(summary(plot_df %>%
                mutate(chose_ax = factor(chose_ax),
                       scenario_completed = factor(scenario_completed)) %>%
                select(-X1, -id)
))
```

## Data

```{r fig.height=7, fig.width=15}
# Plot by the study condition
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(chose_ax = factor(chose_ax)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(chose_ax = fct_recode(chose_ax, no_follow="0", follow = "1")) %>%
    mutate(.fill_column = suggestion_type) %>%
    count(user_id, study_condition, .fill_column, chose_ax, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
          name = "num_follow_ax")

gg_df %>%
  ggplot(aes(user_id, num_follow_ax / num_actions, fill=chose_ax)) +
    geom_bar(stat="identity") +
    geom_hline(yintercept = 0.5) +
    facet_wrap(vars(study_condition), nrow = 1, scales = "free_y") +
    labs(y = "Fraction followed AX") +
    coord_flip() +
    scale_fill_economist()

gg_df %>%
  filter(chose_ax == "follow") %>%
  ggplot(aes(study_condition, num_follow_ax / num_actions, fill=.fill_column)) +
    geom_violin() +
    geom_boxplot(width = 0.1) +
    labs(y = "Fraction followed AX", fill = "noise:has_suggestions") +
    scale_fill_economist()

# Plot by suggestion type
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(chose_ax = factor(chose_ax)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(chose_ax = fct_recode(chose_ax, no_follow="0", follow = "1")) %>%
    count(user_id, suggestion_type, chose_ax, num_actions, noise_level,
          name = "num_follow_ax")

gg_df %>%
  filter(chose_ax == "follow") %>%
  ggplot(aes(suggestion_type, num_follow_ax / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(noise_level), labeller = label_both) +
    labs(y = "Fraction followed AX") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

gg_df %>%
  filter(chose_ax == "follow") %>%
  ggplot(aes(noise_level, num_follow_ax / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(suggestion_type)) +
    labs(y = "Fraction followed AX") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

p1 = gg_df %>%
  filter(chose_ax == "follow") %>%
  ggplot(aes(suggestion_type, num_follow_ax / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .2, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    legend_none()

p2 = gg_df %>%
  filter(chose_ax == "follow") %>%
  ggplot(aes(noise_level, num_follow_ax / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(color = "Type:Noise") +
    theme(legend.position = "right") +
    guides(size = F)

grid.arrange(p1, p2, ncol = 2)
```

## Model

Based on the data, we assume the following structural model:

$$CAX_{ij} = Bernoulli(p_{ij})$$
$$\begin{aligned}
logit(p_{ij}) &= \beta_0 + \beta_{0i} + \beta_{dx}\text{dx}_i +\\
&\beta_{noise_L}\text{noise}_i + \beta_{noise_Q}\text{noise}_i +\\
&\beta_{no}\text{no}_i + \mathbf{\beta_{demo}X_{demo,i}} + \beta_{state} \text{state}_{ij}
\end{aligned}$$
$$\begin{aligned}
\beta_{.} &\sim Normal(0, 10) \\
\beta_{0i} &\sim Normal(0, \sigma_i) \\
\sigma_i &\sim HalfStudent(3, 0, 10)
\end{aligned}$$

The prior for the $\sigma_i$ parameter is the default used in `brms`; I see no need to change it.

Model fitting:

```{r, eval=train_models}
# The null model
chose_ax.model.null = brm(
  chose_ax ~ 0 + Intercept + (1 | user_id),
  family = "bernoulli",
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
chose_ax.model.null = add_criterion(chose_ax.model.null, "waic")
chose_ax.model.null = add_criterion(chose_ax.model.null, "loo", reloo = T)
saveModel(chose_ax.model.null)

# The trend model to see if there is a trend in the noise level variable
chose_ax.model.t = brm(
  chose_ax ~ 0 + Intercept + (has_dx + noise_level) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
chose_ax.model.t = add_criterion(chose_ax.model.t, "waic")
chose_ax.model.t = add_criterion(chose_ax.model.t, "loo", reloo = T)
saveModel(chose_ax.model.t)

# The values model, to see if specific values of the noise level variable are significant
chose_ax.model.v = brm(
  chose_ax ~ 0 + Intercept + (has_dx + noise_level_f) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
chose_ax.model.v = add_criterion(chose_ax.model.v, "waic")
chose_ax.model.v = add_criterion(chose_ax.model.v, "loo", reloo = T)
saveModel(chose_ax.model.v)
```
```{r, eval=!train_models}
# Load the models
chose_ax.model.null = loadModel("chose_ax.model.null")
chose_ax.model.t = loadModel("chose_ax.model.t")
chose_ax.model.v = loadModel("chose_ax.model.v")
```

Model fitting results:

```{r}
print(performance::r2(chose_ax.model.null))

# Print the parameters, and some initial diagnostics
print(model_parameters(chose_ax.model.t,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(chose_ax.model.t))

print(model_parameters(chose_ax.model.v,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(chose_ax.model.v))
```

## Diagnostic

```{r fig.height=7, fig.width=15, eval=plot_diagnostics}
# Alternative diagnostics: diagnostic_posterior(scenario_completed.model.v)

# LOO cross-validation results
print(chose_ax.model.t$criteria$loo$estimates)
print(chose_ax.model.v$criteria$loo$estimates)
print(loo_compare(chose_ax.model.null, chose_ax.model.t, chose_ax.model.v))

# Diagnostics of the sampling process
par(mfrow=c(1,2))
plot(chose_ax.model.t$criteria$loo, main = "Trend Model")
plot(chose_ax.model.v$criteria$loo, main = "Values Model")

# Include posterior predictive checks of the sampling (are sampling according
# to the data that we actually have?)
p0 = pp_check(chose_ax.model.null, type = "bars", stat = "median") + ggtitle("null model")

p1 = pp_check(chose_ax.model.t, type = "bars_grouped", group = "has_dx", stat = "median") + ggtitle("t:has_dx")
p2 = pp_check(chose_ax.model.t, type = "bars_grouped", group = "noise_level", stat = "median") + ggtitle("t:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(chose_ax.model.t), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Trends Model")

p1 = pp_check(chose_ax.model.v, type = "bars_grouped", group = "has_dx", stat = "median") + ggtitle("v:has_dx")
p2 = pp_check(chose_ax.model.v, type = "bars_grouped", group = "noise_level_f", stat = "median") + ggtitle("v:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(chose_ax.model.v), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Values Model")

# Plot predictions vs original
preds_p_df = chose_ax.model.null %>% predict() %>% as_tibble()
p1 =
  preds_p_df %>%
    add_column(chose_ax = chose_ax.model.null$data$chose_ax) %>%
    ggplot(aes(x = Estimate, y = chose_ax, color = chose_ax)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Null Model")

preds_p_df = plot_df %>%
  add_predicted_draws(chose_ax.model.null) %>%
  group_by(chose_ax, .prediction) %>%
  count()
p2 =
  preds_p_df %>%
    ggplot(aes(x = chose_ax, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

preds_p_df = chose_ax.model.t %>% predict() %>% as_tibble()
p3 =
  preds_p_df %>%
    add_column(chose_ax = chose_ax.model.t$data$chose_ax) %>%
    ggplot(aes(x = Estimate, y = chose_ax, color = chose_ax)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Trends Model")

preds_p_df = plot_df %>%
  add_predicted_draws(chose_ax.model.t) %>%
  group_by(chose_ax, .prediction) %>%
  count()
p4 =
  preds_p_df %>%
    ggplot(aes(x = chose_ax, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

# Plot predictions vs original
preds_p_df = chose_ax.model.v %>% predict() %>% as_tibble()
p5 =
  preds_p_df %>%
    add_column(chose_ax = chose_ax.model.v$data$chose_ax) %>%
    ggplot(aes(x = Estimate, y = chose_ax, color = chose_ax)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Values Model")

preds_p_df = plot_df %>%
  add_predicted_draws(chose_ax.model.v) %>%
  group_by(chose_ax, .prediction) %>%
  count()
p6 =
  preds_p_df %>%
    ggplot(aes(x = chose_ax, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

grid.arrange(p1, p3, p5, p2, p4, p6, nrow = 2, ncol = 3)
```

We are better able to recreate the data, if only marginally, with the model.

## Inference

```{r, eval=report_bayesfactors}
# Compute the bayes factor for each parameter value. Note: we compare
# here against the ROPE, and not the degenerate null hypothesis of 0
# Bayes-Factor values would be more significant in the latter case
# According to the Raftery, 1995 rules
# bf = 1 - 3: Weak
# bf = 3 - 20: Positive
# bf = 20 - 150: Strong
# bf > 150: Very strong
print(bayesfactor_rope(chose_ax.model.null, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(chose_ax.model.t, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(chose_ax.model.v, null = c(-0.055, 0.055)), n = 30)
```
```{r}
options(digits = 3)
# Check the significance of each hypothesis
h_df = as_tibble(insight::get_parameters(chose_ax.model.t)) %>%
  transmute(
    Intercept = b_Intercept,
    has_dx_test = -2 * b_has_dx1,
    noise_levelL_test = b_noise_level.L,
    noise_levelQ_test = b_noise_level.Q
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())

h_df = as_tibble(insight::get_parameters(chose_ax.model.v)) %>%
  transmute(
    Intercept = b_Intercept,
    has_dx_test = -2 * b_has_dx1,
    noise_level1_test = b_noise_level_f1,
    noise_level2_test = b_noise_level_f2,
    noise_level3_test = - b_noise_level_f1 - b_noise_level_f2
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())
options(digits = 7)
```

**Results**:

Not really significant result of Linear noise.

(The ROPE is defined as [-0.055, 0.055]. It is the range is suggested in the literature for logistic models and it corresponds to a probability range of 0.11. Therefore, a probability change of less than 0.055 is considered no different from a probability change of 0)

## Posterior Plots

```{r eval=plot_posteriors}
# A visualization data frame
gg_df = plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(chose_ax = factor(chose_ax)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(chose_ax = fct_recode(chose_ax, no_follow="0", follow = "1")) %>%
    count(user_id, chose_ax, num_actions, suggestion_type, has_dx, noise_level,
          name = "num_follow_ax")

# Simulate predictions on new data
p_df =
  plot_df %>%
  data_grid(chose_ax,
            has_dx,
            noise_level_f,
            gender,
            age_group,
            robot_experience,
            num_optimal,
            state_idx_rescaled = seq_range(state_idx_rescaled, n = 4),
            .model = chose_ax.model.v)

fits_p_df = p_df %>%
  add_fitted_draws(chose_ax.model.v, re_formula = NA, seed = default_seed) %>%
  mutate(suggestion_type = ifelse(has_dx == F, "AX", "DXAX")) %>%
  mutate(suggestion_type = factor(suggestion_type, levels = c("AX", "DXAX")))
gc()

pars_p_df = chose_ax.model.t %>%
  extract_draws(newdata = p_df %>% rename(noise_level = noise_level_f), re_formula = NA, nsamples = 100)
gc()

# Plot the posterior distributions. In each of the following, the reference ROPE band
# can be marked based on 3 methods. Make sure to update that ROPE value baased on the
# method that we want to display.

# If centering ROPE on the posterior distributions. Here we center the ROPE around the posterior
# predicted value for the AX condition
preds_p_df = p_df %>%
  add_predicted_draws(chose_ax.model.v, re_formula = NA)  %>% # 0, 1 predictions for each predicted value
  ungroup() %>%
  count(has_dx, noise_level_f, .prediction) %>%
  mutate(suggestion_type = ifelse(has_dx == F, "AX", "DXAX")) %>%
  mutate(suggestion_type = factor(suggestion_type, levels = c("AX", "DXAX")))
rope_value = median(
  preds_p_df %>%
    filter(suggestion_type == "AX") %>%
    spread(.prediction, n) %>%
    mutate(.value = `1` / (`0` + `1`)) %>%
    pull(.value)
)
gc()

gg_df %>%
  filter(chose_ax == 'follow') %>%
  ggplot(aes(x = has_dx, y = num_follow_ax / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_dx, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "CAX", color = "HasDX:Noise")

gg_df %>%
  filter(chose_ax == 'follow') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = num_follow_ax / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_dx, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "CAX", color = "HasDX:Noise")

# Create a plot to show the trend
pars_p_df_X = pars_p_df$dpars$mu$fe$X[,c("Intercept", "noise_level.L")]
pars_p_df_b = pars_p_df$dpars$mu$fe$b[,c("b_Intercept", "b_noise_level.L")]
pars_p_df_y = pars_p_df_X %*% t(pars_p_df_b)
pars_p_df_y = inv_logit_scaled(pars_p_df_y)
p_df =p_df %>%
  bind_cols(as_tibble(pars_p_df_y)) %>%
  gather(key = ".sample", value = ".value", V1:V100) %>%
  rename(noise_level = noise_level_f)
gg_df %>%
  filter(chose_ax == 'follow') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = num_follow_ax / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_line(aes(y = .value, group = .sample, alpha = 0.3), data = p_df) +
    geom_point(aes(color = paste(has_dx, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "CAX", color = "HasDX:Noise") +
    guides(alpha = F)

# Remove the giant fits data frames
rm(preds_p_df) # If using the posterior-predictions-based ROPE
rm(fits_p_df, pars_p_df, pars_p_df_b, pars_p_df_X, pars_p_df_y, p_df, gg_df)
```

```{r eval=plot_paper_posteriors}
eff = fixef(chose_ax.model.t)
ax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  + eff["has_dx1", "Estimate"]
)
dxax_eff = inv_logit_scaled(
  eff["Intercept", "Estimate"]
  - eff["has_dx1", "Estimate"]
)

gg_df = plot_df %>%
  mutate(chose_ax = factor(chose_ax)) %>%
  mutate(chose_ax = fct_recode(chose_ax, no_follow="0", follow="1"),
         has_dx = fct_recode(has_dx, "No DX"="FALSE", "DX"="TRUE"),
         noise_level = fct_recode(noise_level, "Acc: 100%"="0.0", "Acc: 90%"="1.0", "Acc: 80%"="2.0")) %>%
  count(user_id, suggestion_type, chose_ax, num_actions, has_dx, noise_level,
        name = "num_follow_ax") %>%
  mutate(estimate = ifelse(suggestion_type == "AX", ax_eff, -1)) %>%
  mutate(estimate = ifelse(suggestion_type == "DXAX", dxax_eff, estimate))

p1 = gg_df %>%
  filter(chose_ax == "follow") %>%
  ggplot(aes(suggestion_type, num_follow_ax / num_actions, group = suggestion_type, colour=suggestion_type)) +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    scale_y_continuous(limits = c(0.0, 1.2), breaks = c(0.0, 0.5, 1.0)) +
    labs(y = NULL, x = NULL) +
    scale_colour_manual(values = c("#e51400", "#008a00", "#f0a30a", "#a4c400")) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank()) +
    legend_none()

eff = fixef(chose_ax.model.v)
noise_0_eff = inv_logit_scaled(eff["Intercept", "Estimate"] + eff["noise_level_f1","Estimate"])
noise_1_eff = inv_logit_scaled(eff["Intercept", "Estimate"] + eff["noise_level_f2","Estimate"])
noise_2_eff = inv_logit_scaled(eff["Intercept", "Estimate"] - eff["noise_level_f1","Estimate"] - eff["noise_level_f2","Estimate"])

gg_df = gg_df %>%
  mutate(estimate = if_else(noise_level == "Acc: 100%", noise_0_eff, estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 90%", noise_1_eff, estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 80%", noise_2_eff, estimate)) %>%
  mutate(noise_level = fct_rev(noise_level))

p2 = gg_df %>%
  filter(chose_ax == "follow") %>%
  ggplot(aes(noise_level, num_follow_ax / num_actions, group = noise_level, colour = noise_level)) +
    geom_hline(yintercept = inv_logit_scaled(eff["Intercept", "Estimate"]),
               size = .7, linetype = "dashed", color = "grey") +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    annotate("segment",
             x = 3, y = noise_0_eff,
             xend = 2, yend = noise_1_eff,
             colour = "black") +
    annotate("segment",
             x = 1, y = noise_2_eff,
             xend = 2, yend = noise_1_eff,
             color = "black") +
    annotate("text",
             x = 3.5,
             y = inv_logit_scaled(eff["Intercept", "Estimate"] - 0.35),
             label = "Mean of all levels",
             angle = 90,
             group = NA,
             colour = "black") +
    scale_y_continuous(limits = c(0.0, 1.0), breaks = c(0.0, 0.5, 1.0)) +
    labs(y = "RDX", x = NULL) +
    scale_colour_manual(values = c("#e51400", "#008a00", "#f0a30a", "#a4c400")) +
    scale_size_area(max_size = 1) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
    legend_none()

grid.arrange(p1, p2, nrow = 1, ncol = 2)
rm(p1, p2)
```

```{r, echo=F, results=F, message=F, warning=F}
rm(chose_ax.model.null, chose_ax.model.t, chose_ax.model.v)
gc()
```


# CDX: Compliance with DX Suggestions

**Did the user take an follow the DX suggestions that were provided to them?**

In the code, the variable might be referred to as `chose_dx`, `follow_dx`, etc. depending on the version of the codebase


```{r}
plot_df = actions %>%
  filter(has_dx == T) %>%
  select(X1, id, user_id, study_condition, start_condition, num_optimal,
         state_idx, state_idx_rescaled,
         age_group, gender, robot_experience,
         noise_level, noise_level_f, has_noise, suggestion_type,
         has_dx, has_ax, has_ax_only, has_dx_only, has_dxax,
         scenario_completed, num_actions, chose_dx)

# With these dropped levels, the suggestion_type variable is the same as the
# boolean flags for each suggestion type
plot_df$suggestion_type = droplevels(plot_df$suggestion_type)

print(summary(plot_df %>%
                mutate(chose_dx = factor(chose_dx),
                       scenario_completed = factor(scenario_completed)) %>%
                select(-X1, -id)
))
```

## Data

```{r fig.height=7, fig.width=15}
# Plot by the study condition
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(chose_dx = factor(chose_dx)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(chose_dx = fct_recode(chose_dx, no_follow="0", follow = "1")) %>%
    mutate(.fill_column = suggestion_type) %>%
    count(user_id, study_condition, .fill_column, chose_dx, num_actions, has_ax_only, has_dx_only, has_dxax, noise_level,
          name = "num_follow_dx")

gg_df %>%
  ggplot(aes(user_id, num_follow_dx / num_actions, fill=chose_dx)) +
    geom_bar(stat="identity") +
    geom_hline(yintercept = 0.5) +
    facet_wrap(vars(study_condition), nrow = 1, scales = "free_y") +
    labs(y = "Fraction followed DX") +
    coord_flip() +
    scale_fill_economist()

gg_df %>%
  filter(chose_dx == "follow") %>%
  ggplot(aes(study_condition, num_follow_dx / num_actions, fill=.fill_column)) +
    geom_violin() +
    geom_boxplot(width = 0.1) +
    labs(y = "Fraction followed DX", fill = "noise:has_suggestions") +
    scale_fill_economist()

# Plot by suggestion type
gg_df =
  plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(chose_dx = factor(chose_dx)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(chose_ax = fct_recode(chose_dx, no_follow="0", follow = "1")) %>%
    count(user_id, suggestion_type, chose_dx, num_actions, noise_level,
          name = "num_follow_dx")

gg_df %>%
  filter(chose_dx == "1") %>%
  ggplot(aes(suggestion_type, num_follow_dx / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(noise_level), labeller = label_both) +
    labs(y = "Fraction followed DX") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

gg_df %>%
  filter(chose_dx == "1") %>%
  ggplot(aes(noise_level, num_follow_dx / num_actions, fill=suggestion_type)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(cols = vars(suggestion_type)) +
    labs(y = "Fraction followed DX") +
    scale_fill_economist() +
    theme(legend.position = "bottom")

p1 = gg_df %>%
  filter(chose_dx == "1") %>%
  ggplot(aes(suggestion_type, num_follow_dx / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .2, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    legend_none()

p2 = gg_df %>%
  filter(chose_dx == "1") %>%
  ggplot(aes(noise_level, num_follow_dx / num_actions)) +
    geom_violin() +
    geom_point(aes(color = paste(suggestion_type, noise_level, sep = ":")),
               size = 2, position = position_jitter(width = .1, height = 0)) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(color = "Type:Noise") +
    theme(legend.position = "right") +
    guides(size = F)

grid.arrange(p1, p2, ncol = 2)
```

## Model

Based on the data, we assume the following structural model:

$$cdx_{ij} = Bernoulli(p_{ij})$$
$$\begin{aligned}
logit(p_{ij}) &= \beta_0 + \beta_{0i} + \beta_{ax}\text{ax}_i +\\
&\beta_{noise_L}\text{noise}_i + \beta_{noise_Q}\text{noise}_i +\\
&\beta_{no}\text{no}_i + \mathbf{\beta_{demo}X_{demo,i}} + \beta_{state} \text{state}_{ij}
\end{aligned}$$
$$\begin{aligned}
\beta_{.} &\sim Normal(0, 10) \\
\beta_{0i} &\sim Normal(0, \sigma_i) \\
\sigma_i &\sim HalfStudent(3, 0, 10)
\end{aligned}$$

The prior for the $\sigma_i$ parameter is the default used in `brms`; I see no need to change it.

Model fitting:

```{r, eval=train_models}
# The null model
chose_dx.model.null = brm(
  chose_dx ~ 0 + Intercept + (1 | user_id),
  family = "bernoulli",
  prior = set_prior("normal(0, 10)", class = "b"),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
chose_dx.model.null = add_criterion(chose_dx.model.null, "waic")
chose_dx.model.null = add_criterion(chose_dx.model.null, "loo", reloo = T)
saveModel(chose_dx.model.null)

# The trend model to see if there is a trend in the noise level variable
chose_dx.model.t = brm(
  chose_dx ~ 0 + Intercept + (has_ax + noise_level) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
chose_dx.model.t = add_criterion(chose_dx.model.t, "waic")
chose_dx.model.t = add_criterion(chose_dx.model.t, "loo", reloo = T)
saveModel(chose_dx.model.t)

# The values model, to see if specific values of the noise level variable are significant
chose_dx.model.v = brm(
  chose_dx ~ 0 + Intercept + (has_ax + noise_level_f) + (age_group + robot_experience + gender) + num_optimal + state_idx_rescaled + (1 | user_id),
  family = bernoulli,
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 10)", class = "sd")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
chose_dx.model.v = add_criterion(chose_dx.model.v, "waic")
chose_dx.model.v = add_criterion(chose_dx.model.v, "loo", reloo = T)
saveModel(chose_dx.model.v)
```
```{r, eval=!train_models}
# Load the models
chose_dx.model.null = loadModel("chose_dx.model.null")
chose_dx.model.t = loadModel("chose_dx.model.t")
chose_dx.model.v = loadModel("chose_dx.model.v")
```

Model fitting results:

```{r}
print(performance::r2(chose_dx.model.null))

# Print the parameters, and some initial diagnostics
print(model_parameters(chose_dx.model.t,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(chose_dx.model.t))

print(model_parameters(chose_dx.model.v,
                       centrality = "median",
                       ci = 0.89,
                       ci_method = "hdi",
                       test = c("pd", "rope"),
                       rope_range = c(-0.055, 0.055),
                       rope_ci = 1,
                       effects = "fixed"))
print(performance::r2(chose_dx.model.v))
```

## Diagnostic

```{r fig.height=7, fig.width=15, eval=plot_diagnostics}
# Alternative diagnostics: diagnostic_posterior(scenario_completed.model.v)

# LOO cross-validation results
print(chose_dx.model.t$criteria$loo$estimates)
print(chose_dx.model.v$criteria$loo$estimates)
print(loo_compare(chose_dx.model.null, chose_dx.model.t, chose_dx.model.v))

# Diagnostics of the sampling process
par(mfrow=c(1,2))
plot(chose_dx.model.t$criteria$loo, main = "Trend Model")
plot(chose_dx.model.v$criteria$loo, main = "Values Model")

# Include posterior predictive checks of the sampling (are sampling according
# to the data that we actually have?)
p0 = pp_check(chose_dx.model.null, type = "bars", stat = "median") + ggtitle("null model")

p1 = pp_check(chose_dx.model.t, type = "bars_grouped", group = "has_ax", stat = "median") + ggtitle("t:has_ax")
p2 = pp_check(chose_dx.model.t, type = "bars_grouped", group = "noise_level", stat = "median") + ggtitle("t:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(chose_dx.model.t), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Trends Model")

p1 = pp_check(chose_dx.model.v, type = "bars_grouped", group = "has_ax", stat = "median") + ggtitle("v:has_ax")
p2 = pp_check(chose_dx.model.v, type = "bars_grouped", group = "noise_level_f", stat = "median") + ggtitle("v:noise_level")
grid.arrange(p1, p2, p0, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(chose_dx.model.v), regex_pars = "b_|^shape", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Values Model")

# Plot predictions vs original
preds_p_df = chose_dx.model.null %>% predict() %>% as_tibble()
p1 =
  preds_p_df %>%
    add_column(chose_dx = chose_dx.model.null$data$chose_dx) %>%
    ggplot(aes(x = Estimate, y = chose_dx, color = chose_dx)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Null Model")

preds_p_df = plot_df %>%
  add_predicted_draws(chose_dx.model.null) %>%
  group_by(chose_dx, .prediction) %>%
  count()
p2 =
  preds_p_df %>%
    ggplot(aes(x = chose_dx, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

preds_p_df = chose_dx.model.t %>% predict() %>% as_tibble()
p3 =
  preds_p_df %>%
    add_column(chose_dx = chose_dx.model.t$data$chose_dx) %>%
    ggplot(aes(x = Estimate, y = chose_dx, color = chose_dx)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Trends Model")

preds_p_df = plot_df %>%
  add_predicted_draws(chose_dx.model.t) %>%
  group_by(chose_dx, .prediction) %>%
  count()
p4 =
  preds_p_df %>%
    ggplot(aes(x = chose_dx, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

# Plot predictions vs original
preds_p_df = chose_dx.model.v %>% predict() %>% as_tibble()
p5 =
  preds_p_df %>%
    add_column(chose_dx = chose_dx.model.v$data$chose_dx) %>%
    ggplot(aes(x = Estimate, y = chose_dx, color = chose_dx)) +
      geom_point() +
      labs(x = "Predicted values") +
      ylim(0, 1) +
      xlim(0, 1) +
      ggtitle("Values Model")

preds_p_df = plot_df %>%
  add_predicted_draws(chose_dx.model.v) %>%
  group_by(chose_dx, .prediction) %>%
  count()
p6 =
  preds_p_df %>%
    ggplot(aes(x = chose_dx, y = .prediction, fill = n / sum(preds_p_df$n))) +
      geom_tile() +
      geom_text(aes(label = sprintf("%1.2f", n / sum(preds_p_df$n))), size = 10, vjust = 1) +
      scale_fill_gradient(limits = c(0, 1))

grid.arrange(p1, p3, p5, p2, p4, p6, nrow = 2, ncol = 3)
```

We are able to recreate the data with the model; although no differently than from the null model.

## Inference

```{r, eval=report_bayesfactors}
# Compute the bayes factor for each parameter value. Note: we compare
# here against the ROPE, and not the degenerate null hypothesis of 0
# Bayes-Factor values would be more significant in the latter case
# According to the Raftery, 1995 rules
# bf = 1 - 3: Weak
# bf = 3 - 20: Positive
# bf = 20 - 150: Strong
# bf > 150: Very strong
print(bayesfactor_rope(chose_dx.model.null, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(chose_dx.model.t, null = c(-0.055, 0.055)), n = 30)
print(bayesfactor_rope(chose_dx.model.v, null = c(-0.055, 0.055)), n = 30)
```
```{r}
options(digits = 3)
# Check the significance of each hypothesis
h_df = as_tibble(insight::get_parameters(chose_dx.model.t)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = -2 * b_has_ax1,
    noise_levelL_test = b_noise_level.L,
    noise_levelQ_test = b_noise_level.Q
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())

h_df = as_tibble(insight::get_parameters(chose_dx.model.v)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = -2 * b_has_ax1,
    noise_level1_test = b_noise_level_f1,
    noise_level2_test = b_noise_level_f2,
    noise_level3_test = - b_noise_level_f1 - b_noise_level_f2
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-0.055, 0.055))
print(hyp_results %>% as.matrix())
options(digits = 7)
```

**Results**:

1. Noise Level Linear
    - Negative (negative slope) pd = 100%
    - Median = -0.77, 89% CI [-1.11, -0.39]
    - Small, Effect Size = 0.42
    - 0.08% in ROPE

(The ROPE is defined as [-0.055, 0.055]. It is the range is suggested in the literature for logistic models and it corresponds to a probability range of 0.11. Therefore, a probability change of less than 0.055 is considered no different from a probability change of 0)

## Posterior Plots

```{r eval=plot_posteriors}
# A visualization data frame
gg_df = plot_df %>%
    mutate(noise_level = fct_rev(noise_level)) %>%
    mutate(chose_dx = factor(chose_dx)) %>%
    mutate(user_id = factor(user_id)) %>%
    mutate(chose_dx = fct_recode(chose_dx, no_follow="0", follow = "1")) %>%
    mutate(.fill_column = paste(noise_level, !(study_condition == 'BASELINE'), sep = ":")) %>%
    count(user_id, study_condition, .fill_column, chose_dx, num_actions, has_ax, has_dx, noise_level,
          name = "num_follow_dx")

# Simulate predictions on new data
p_df =
  plot_df %>%
  data_grid(chose_dx,
            has_ax,
            noise_level_f,
            gender,
            age_group,
            robot_experience,
            num_optimal,
            state_idx_rescaled = seq_range(state_idx_rescaled, n = 4),
            .model = chose_dx.model.v)

fits_p_df = p_df %>% add_fitted_draws(chose_dx.model.v,
                                      re_formula = NA,
                                      n = 100,
                                      seed = default_seed)
gc()
pars_p_df = chose_dx.model.t %>%
  extract_draws(newdata = p_df %>% rename(noise_level = noise_level_f),
                re_formula = NA,
                nsamples = 100)
gc()

# We don't want predicted draws because that's a raw count of ones and zeros; not the
# probability distribution
# preds_p_df = p_df %>% add_predicted_draws(scenario_completed.model.v)

# Plot the posterior distributions
rope_value = gg_df %>%
  filter(chose_dx == 'follow', has_ax == F) %>%
  summarise(.value = median(num_follow_dx / num_actions)) %>%
  pull(.value)
gg_df %>%
  filter(chose_dx == 'follow') %>%
  ggplot(aes(x = has_ax, y = num_follow_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax, has_dx, noise_level, sep = ":")), size = 2) +
    stat_summary(fun.y = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "follow_dx", color = "AX:DX:Noise")

rope_value = gg_df %>%
  filter(chose_dx == 'follow', noise_level == "0.0") %>%
  summarise(.value = median(num_follow_dx / num_actions)) %>%
  pull(.value)
gg_df %>%
  filter(chose_dx == 'follow') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = num_follow_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_point(aes(color = paste(has_ax, has_dx, noise_level, sep = ":")), size = 2) +
    stat_summary(fun.y = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "follow_dx", color = "AX:DX:Noise")

# Create a plot to show the trend
pars_p_df_X = pars_p_df$dpars$mu$fe$X[,c("Intercept", "noise_level.L")]
pars_p_df_b = pars_p_df$dpars$mu$fe$b[,c("b_Intercept", "b_noise_level.L")]
pars_p_df_y = pars_p_df_X %*% t(pars_p_df_b)
pars_p_df_y = inv_logit_scaled(pars_p_df_y)
p_df =
  p_df %>%
  bind_cols(as_tibble(pars_p_df_y)) %>%
  gather(key = ".sample", value = ".value", V1:V100) %>%
  rename(noise_level = noise_level_f)

rope_value = gg_df %>%
  filter(chose_dx == 'follow', noise_level == "0.0") %>%
  summarise(.value = median(num_follow_dx / num_actions)) %>%
  pull(.value)
gg_df %>%
  filter(chose_dx == 'follow') %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  ggplot(aes(x = noise_level, y = num_follow_dx / num_actions)) +
    geom_rect(ymin = rope_value-0.055, ymax = rope_value+0.055,
              xmin = -Inf, xmax = Inf,
              color = "transparent", fill = "white") +
    annotate("text", x = 0.5, y = rope_value, label = "ROPE", angle = 90) +
    stat_halfeye(aes(y = .value, x = noise_level_f), data = fits_p_df, position = position_nudge(x = 0.1)) +
    geom_line(aes(y = .value, group = .sample, alpha = 0.3), data = p_df) +
    geom_point(aes(color = paste(has_ax, has_dx, noise_level, sep = ":")), size = 2) +
    stat_summary(fun.y = median, geom = "point", shape = 23, size = 6) +
    scale_color_metro() +
    ylim(0, 1) +
    labs(y = "scenario_completed", color = "AX:DX:Noise") +
    guides(alpha = F)

# Remove the giant fits data frames
rm(fits_p_df, pars_p_df, pars_p_df_b, pars_p_df_X, pars_p_df_y, p_df, gg_df)
```

```{r eval=plot_posteriors}
plot_df = actions %>%
  filter(has_dx == T) %>%
  select(X1, id, user_id, study_condition, start_condition, num_optimal,
         state_idx, state_idx_rescaled,
         age_group, gender, robot_experience,
         noise_level, noise_level_f, has_noise, has_dx, has_ax,
         scenario_completed, num_actions, chose_dx) %>%
  mutate(scenario_completed = factor(scenario_completed)) %>%
  mutate(scenario_completed = fct_recode(scenario_completed, Unresolved="0", Resolved = "1"),
         has_ax = fct_recode(has_ax, "No AX"="FALSE", "AX"="TRUE"),
         noise_level = fct_recode(noise_level, "Acc: 100%"="0.0", "Acc: 90%"="1.0", "Acc: 80%"="2.0"))

eff = fixef(chose_dx.model.v)

gg_df = plot_df %>%
  mutate(.fill_column = paste(noise_level, !(study_condition == 'BASELINE'), sep = ":")) %>%
  count(user_id, study_condition, .fill_column, chose_dx, num_actions, has_ax, noise_level,
        name = "num_chose_dx") %>%
  mutate(estimate = -1) %>%
  mutate(estimate = if_else(noise_level == "Acc: 100%", inv_logit_scaled(eff["noise_level_f1","Estimate"] + eff["Intercept", "Estimate"]), estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 90%", inv_logit_scaled(eff["noise_level_f2","Estimate"] + eff["Intercept", "Estimate"]), estimate)) %>%
  mutate(estimate = if_else(noise_level == "Acc: 80%", inv_logit_scaled(eff["Intercept", "Estimate"] - eff["noise_level_f1","Estimate"] - eff["noise_level_f2","Estimate"]), estimate)) %>%
  mutate(noise_level = fct_rev(noise_level))

gg_df %>%
  filter(chose_dx == "1") %>%
  ggplot(aes(noise_level, num_chose_dx / num_actions, group = noise_level, colour = noise_level)) +
    geom_hline(yintercept = inv_logit_scaled(eff["Intercept", "Estimate"]),
               size = .7, linetype = "dashed", color = "grey") +
    geom_count(aes(colour = NULL)) +
    geom_boxplot(aes(y = estimate)) +
    annotate("segment",
             x = 3,
             y = inv_logit_scaled(eff["noise_level_f1","Estimate"] + eff["Intercept", "Estimate"]),
             xend = 2,
             yend = inv_logit_scaled(eff["noise_level_f2","Estimate"] + eff["Intercept", "Estimate"]),
             colour = "black") +
    annotate("segment",
             x = 1,
             y = inv_logit_scaled(eff["Intercept", "Estimate"] - eff["noise_level_f1","Estimate"] - eff["noise_level_f2","Estimate"]),
             xend = 2,
             yend = inv_logit_scaled(eff["noise_level_f2","Estimate"] + eff["Intercept", "Estimate"]),
             color = "black") +
    annotate("text",
             x = 3.5,
             y = inv_logit_scaled(eff["Intercept", "Estimate"] - 0.25),
             label = "Mean of all levels",
             angle = 90,
             group = NA,
             colour = "black") +
    scale_y_continuous(limits = c(0.0, 1.0), breaks = c(0.0, 0.5, 1.0)) +
    labs(y = "Fraction of participants that resolved fault", x = NULL) +
    scale_colour_manual(values = c("#d62728", "#2ca02c", "#ff7f0e")) +
    scale_size_area(max_size = 1) +
    theme_economist_white(base_size = 13) +
    theme(plot.background = element_rect(fill = "white"),
          axis.title.y = element_blank()) +
    legend_none()
```

```{r, echo=F, results=F, message=F, warning=F}
rm(chose_dx.model.null, chose_dx.model.t, chose_dx.model.v)
gc()
```


# SUS: System Usability Scale

```{r}
plot_df = users %>%
  select(X1, id, study_condition, start_condition, num_optimal,
         age_group, gender, robot_experience,
         noise_level, noise_level_f, has_noise,
         has_dx, has_ax, has_ax_only, has_dx_only, has_dxax,
         sus, scenario_completed) %>%
  mutate(scenario_completed = factor(scenario_completed))

text_short(report(plot_df))
```

## Data

```{r fig.height=7, fig.width=15}
# Plot by the study condition
plot_df %>%
  mutate(.fill_column = paste(noise_level, !(study_condition == 'BASELINE'), sep = ":")) %>%
  ggplot(aes(study_condition, sus, fill = .fill_column)) +
    geom_boxplot() +
    geom_count() +
    labs(y = "Number unnecessary actions", fill = "noise:has_suggestions") +
    scale_fill_economist()

# Visualize the data by the three variables that we care about
gg_df = plot_df %>%
  mutate(.fill_column = paste(noise_level, !(study_condition == 'BASELINE'), sep = ":")) %>%
  mutate(noise_level = fct_rev(noise_level))

p1 = gg_df %>%
  ggplot(aes(has_ax, sus, fill=.fill_column)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(rows = vars(noise_level), cols = vars(has_dx), labeller = label_both) +
    labs(y = "Number unnecessary actions") +
    scale_fill_economist()

p2 = gg_df %>%
  ggplot(aes(has_dx, sus, fill=.fill_column)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(rows = vars(noise_level), cols = vars(has_ax), labeller = label_both) +
    labs(y = "Number unnecessary actions") +
    scale_fill_economist()

p3 = gg_df %>%
  mutate(noise_level = fct_rev(noise_level)) %>%
  mutate(has_ax = factor(has_ax)) %>%
  mutate(has_ax = fct_rev(has_ax)) %>%
  ggplot(aes(noise_level, sus, fill=.fill_column)) +
    geom_boxplot() +
    geom_count() +
    facet_grid(rows = vars(has_ax), cols = vars(has_dx), labeller = label_both) +
    labs(y = "Number unnecessary actions") +
    scale_fill_economist()

grid.arrange(p1, p2, p3, ncol = 3)

# Visualize also the variation in each of the three levels that we care about
p1 = gg_df %>%
  ggplot(aes(sus)) +
    geom_histogram(binwidth = 10) +
    facet_grid(rows = vars(has_ax)) +
    ylim(0, 30) +
    scale_fill_economist() +
    legend_none()

p2 = gg_df %>%
  ggplot(aes(sus)) +
    geom_histogram(binwidth = 10) +
    facet_grid(rows = vars(has_dx)) +
    ylim(0, 30) +
    scale_fill_economist() +
    theme(legend.position = "bottom")

p3 = gg_df %>%
  ggplot(aes(sus)) +
    geom_histogram(binwidth = 10) +
    facet_grid(rows = vars(noise_level)) +
    ylim(0, 30) +
    scale_fill_economist() +
    legend_none()

grid.arrange(p1, p2, p3, ncol = 3)
```

## Model

Based on the data, we assume a skew-normal linear model:

$$sus_i = SkewNormal(\mu_i, \sigma, \alpha)$$
$$\begin{aligned}
\mu_i &= \beta_0 + \beta_{ax}\text{ax}_i + \beta_{dx}\text{dx}_i + \beta_{noise}\text{noise}_i +\\ &\beta_{ax:noise}\text{ax}_i\text{noise}_i + \beta_{dx:noise}\text{dx}_i\text{noise}_i + \\
&\beta_{no}\text{no}_i + \mathbf{\beta_{demo}X_{demo,i}}
\end{aligned}$$
$$\begin{aligned}
\beta_{.} &\sim Normal(0, 10) \\
\sigma &\sim HalfStudent(3, 0, 22) \\
\alpha &\sim Normal(0, 4)
\end{aligned}$$

The prior for the $\sigma, \alpha$ parameters are the default used in `brms`; I see no need to change it.

Model fitting:

```{r, eval=train_models}
# A null model to compare against
sus.model.null = brm(
  sus ~ 0 + Intercept,
  family = "skew_normal",
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 22)", class = "sigma"),
            set_prior("normal(0, 4)", class = "alpha")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
sus.model.null = add_criterion(sus.model.null, "waic")
sus.model.null = add_criterion(sus.model.null, "loo", reloo = T)
saveModel(sus.model.null)

# The trend model to see if there is a trend in the noise level variable
sus.model.t = brm(
  sus ~ 0 + Intercept + (has_ax_only + has_dx_only + has_dxax + noise_level) + (gender + age_group + robot_experience) + num_optimal,
  family = "skew_normal",
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 22)", class = "sigma"),
            set_prior("normal(0, 4)", class = "alpha")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
sus.model.t = add_criterion(sus.model.t, "waic")
sus.model.t = add_criterion(sus.model.t, "loo", reloo = T)
saveModel(sus.model.t)

# The values model, to see if specific values of the noise level variable are significant
sus.model.v = brm(
  sus ~ 0 + Intercept + (has_ax_only + has_dx_only + has_dxax + noise_level_f) + (gender + age_group + robot_experience) + num_optimal,
  family = "skew_normal",
  prior = c(set_prior("normal(0, 10)", class = "b"),
            set_prior("student_t(3, 0, 22)", class = "sigma"),
            set_prior("normal(0, 4)", class = "alpha")),
  data = plot_df,
  seed = default_seed,
  save_all_pars = T,
  sample_prior = T
)
sus.model.v = add_criterion(sus.model.v, "waic")
sus.model.v = add_criterion(sus.model.v, "loo", reloo = T)
saveModel(sus.model.v)
# More model plots are available at:
# https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/counting-and-classification.html

# Attempted RStanarm models: The estimate contrasts doesn't seem to be as helpful?
# scenario_completed.model.v = stan_glm(
#   scenario_completed ~ ((has_dx + has_ax) * noise_level) + (gender + age_group + robot_experience) + num_optimal,
#   family = binomial(link = "logit"),
#   prior = normal(0, 10),
#   prior_intercept = normal(0, 10),
#   data = plot_df,
#   QR = T,
#   seed = default_seed
# )
```
```{r, eval=!train_models}
# Load the models
sus.model.null = loadModel("sus.model.null")
sus.model.t = loadModel("sus.model.t")
sus.model.v = loadModel("sus.model.v")
```

Model fitting results:

```{r}
# print(summary(sus.model.null))
print(performance::r2(sus.model.null))

# Print the parameters, and some initial diagnostics
print(tidy_stan(sus.model.t))
print(performance::r2(sus.model.t))

print(tidy_stan(sus.model.v))
print(performance::r2(sus.model.v))
```

## Diagnostic

```{r fig.height=7, fig.width=15, eval=plot_diagnostics}
# Alternative diagnostics: diagnostic_posterior(scenario_completed.model.v)

# LOO cross-validation results
print(sus.model.t$criteria$loo$estimates)
print(sus.model.v$criteria$loo$estimates)
print(loo_compare(sus.model.null,
                  sus.model.t,
                  sus.model.v))

# Diagnostics of the sampling process
par(mfrow=c(1,2))
plot(sus.model.t$criteria$loo, main = "Trend Model")
plot(sus.model.v$criteria$loo, main = "Values Model")

# Include posterior predictive checks of the sampling (are sampling according
# to the data that we actually have?)
mcmc_intervals(as.matrix(sus.model.null), regex_pars = "b_", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Null Model")

p1 = pp_check(sus.model.t, group = "has_ax_only", stat = "median") + ggtitle("t:has_ax")
p2 = pp_check(sus.model.t, group = "has_dx_only", stat = "median") + ggtitle("t:has_dx")
p3 = pp_check(sus.model.t, group = "has_dxax", stat = "median") + ggtitle("t:has_dxax")
p4 = pp_check(sus.model.t, group = "noise_level", stat = "median") + ggtitle("t:noise_level")
grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(sus.model.t), regex_pars = "b_", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Trends Model")

p1 = pp_check(sus.model.v, group = "has_ax_only", stat = "median") + ggtitle("v:has_ax")
p2 = pp_check(sus.model.v, group = "has_dx_only", stat = "median") + ggtitle("v:has_dx")
p3 = pp_check(sus.model.v, group = "has_dxax", stat = "median") + ggtitle("v:has_dxax")
p4 = pp_check(sus.model.v, group = "noise_level_f") + ggtitle("v:noise_level")
grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
mcmc_intervals(as.matrix(sus.model.v), regex_pars = "b_", prob = 0.90, prob_outer = 0.95) +
  ggtitle("Values Model")

# Plot predictions vs original
preds_p_df = sus.model.null %>% predict() %>% as_tibble()
p1 =
  preds_p_df %>%
    add_column(sus = sus.model.null$data$sus) %>%
    ggplot(aes(x = sus, y = Estimate)) +
      geom_point() +
      labs(y = "Predicted values") +
      ggtitle("Null Model")

preds_p_df = sus.model.t %>% predict() %>% as_tibble()
p3 =
  preds_p_df %>%
    add_column(sus = sus.model.t$data$sus) %>%
    ggplot(aes(x = sus, y = Estimate)) +
      geom_point() +
      labs(y = "Predicted values") +
      ggtitle("Trends Model")

preds_p_df = sus.model.v %>% predict() %>% as_tibble()
p5 =
  preds_p_df %>%
    add_column(sus = sus.model.v$data$sus) %>%
    ggplot(aes(x = sus, y = Estimate)) +
      geom_point() +
      labs(y = "Predicted values") +
      ggtitle("Values Model")

grid.arrange(p1, p3, p5, nrow = 1, ncol = 3)
```

## Inference

```{r, eval=report_bayesfactors}
# Compute the bayes factor for each parameter value. Note: we compare
# here against the ROPE, and not the degenerate null hypothesis of 0
# Bayes-Factor values would be more significant in the latter case
# According to the Raftery, 1995 rules
# bf = 1 - 3: Weak
# bf = 3 - 20: Positive
# bf = 20 - 150: Strong
# bf > 150: Very strong
print(bayesfactor_rope(sus.model.null), n = 30)
print(bayesfactor_rope(sus.model.t), n = 30)
print(bayesfactor_rope(sus.model.v), n = 30)
```
```{r}
# Compare the models. Note: we cannot do this because we don't have enough samples.
# The default is 4000; apparently these functions are only meaningful with 40000
# comparison = bayesfactor_models(scenario_completed.model.t, scenario_completed.model.v,
#                                 denominator = scenario_completed.model.null)
# print(comparison)
# print(bayesfactor_inclusion(comparison))

# # If we're using the brms functions, then use the following (make sure to update!)
# common_hyp_to_test = c("-2 * has_ax1 = 0", "-2 * has_dx1 = 0")
# noise_levels_hyp_to_test = c(
#   "Intercept-noise_level_f1 = 0", "Intercept-noise_level_f2 = 0", "Intercept-noise_level_f1-noise_level_f2 = 0",
#   "Intercept-has_ax1:noise_level_f1 = 0", "Intercept-has_dx1:noise_level_f1 = 0",
#   "Intercept-has_ax1:noise_level_f2 = 0", "Intercept-has_dx1:noise_level_f2 = 0",
#   "Intercept-has_ax1:noise_level_f1-has_ax1:noise_level_f2 = 0",
#   "Intercept-has_dx1:noise_level_f1-has_dx1:noise_level_f2 = 0"
# )
# hyp_results = test_hypotheses(hypotheses_list = c(common_hyp_to_test, noise_levels_hyp_to_test), model = scenario_completed.model.v)
# print(hyp_results$hypothesis)
# plot(hyp_results, ask=F)

options(digits = 3)
# Check the significance of each hypothesis
h_df = as_tibble(insight::get_parameters(sus.model.t)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = -2 * b_has_ax_only1,
    has_dx_test = -2 * b_has_dx_only1,
    has_dxax_test = -2 * b_has_dxax1,
    noise_levelL_test = b_noise_level.L,
    noise_levelQ_test = b_noise_level.Q
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-2.3, 2.3))
print(hyp_results %>% select(Parameter, pd, HDI_low, HDI_high, ROPE_Percentage, ROPE_Equivalence) %>% as.matrix())

h_df = as_tibble(insight::get_parameters(sus.model.v)) %>%
  transmute(
    Intercept = b_Intercept,
    has_ax_test = -2 * b_has_ax_only1,
    has_dx_test = -2 * b_has_dx_only1,
    has_dxax_test = -2 * b_has_dxax1,
    noise_level1_test = b_noise_level_f1,
    noise_level2_test = b_noise_level_f2,
    noise_level3_test = - b_noise_level_f1 - b_noise_level_f2
  )

hyp_results = test_hypotheses(h_df, rope_values = c(-2.3, 2.3))
print(hyp_results %>% select(Parameter, pd, HDI_low, HDI_high, ROPE_Percentage, ROPE_Equivalence) %>% as.matrix())
options(digits = 7)
```

**Results**:

There is no significant effect of any of the suggestions parameters on the SUS.

(The ROPE is defined as [-2.3, 2.3]. It corresponds to `0.1 * SD` of the output)

There are no posterior plots to show (all effects are supposedly non-existent).

```{r, echo=F, results=F, message=F, warning=F}
rm(sus.model.null, sus.model.t, sus.model.v)
gc()
```

